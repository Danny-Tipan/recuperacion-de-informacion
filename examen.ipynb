{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d4ac2a74",
   "metadata": {},
   "source": [
    "## Examen"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c7a6207",
   "metadata": {},
   "source": [
    "**Nombre: Danny Tipan**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd4ce4bb",
   "metadata": {},
   "source": [
    "## Importaciones y Descarga de Recursos NLTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a66ec4f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Verificando recursos de NLTK...\n",
      "Recursos de NLTK asegurados.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import nltk\n",
    "import re\n",
    "import os \n",
    "print(\"Verificando recursos de NLTK...\")\n",
    "try:\n",
    "    nltk.data.find('corpora/stopwords')\n",
    "except nltk.downloader.DownloadError:\n",
    "    nltk.download('stopwords')\n",
    "    print(\"Recurso 'stopwords' de NLTK descargado.\")\n",
    "\n",
    "try:\n",
    "    nltk.data.find('tokenizers/punkt')\n",
    "except nltk.downloader.DownloadError:\n",
    "    nltk.download('punkt')\n",
    "    print(\"Recurso 'punkt' de NLTK descargado.\")\n",
    "\n",
    "print(\"Recursos de NLTK asegurados.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37e96c84",
   "metadata": {},
   "source": [
    "## Creación del Subconjunto del Corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7e4be598",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El archivo subconjunto 'data/arxiv_subset_1_percent.jsonl' ya existe. ¡Saltando la generación del subconjunto!\n"
     ]
    }
   ],
   "source": [
    "# --- CONFIGURACIÓN DE RUTAS DE ARCHIVOS ---\n",
    "LARGE_CORPUS_FILE_PATH = 'data/arxiv-metadata-oai-snapshot.json'\n",
    "SUBSET_CORPUS_FILE_PATH = 'data/arxiv_subset_1_percent.jsonl'\n",
    "QUERIES_FILE_PATH = 'data/queries.txt'\n",
    "\n",
    "# --- GENERACIÓN DEL SUBSET DEL 1% ---\n",
    "NUM_DOCS_TO_KEEP = 25000 \n",
    "\n",
    "if not os.path.exists(SUBSET_CORPUS_FILE_PATH):\n",
    "    print(f\"El archivo subconjunto '{SUBSET_CORPUS_FILE_PATH}' no existe.\")\n",
    "    print(f\"Generando subconjunto de aproximadamente {NUM_DOCS_TO_KEEP} documentos desde '{LARGE_CORPUS_FILE_PATH}'...\")\n",
    "\n",
    "    if not os.path.exists(LARGE_CORPUS_FILE_PATH):\n",
    "        print(f\"Error: El archivo original grande '{LARGE_CORPUS_FILE_PATH}' no fue encontrado.\")\n",
    "        print(\"Asegúrate de haberlo colocado en la carpeta 'data/'.\")\n",
    "    else:\n",
    "        count = 0\n",
    "        with open(LARGE_CORPUS_FILE_PATH, 'r', encoding='utf-8') as infile, \\\n",
    "             open(SUBSET_CORPUS_FILE_PATH, 'w', encoding='utf-8') as outfile:\n",
    "            for line in infile:\n",
    "                if count < NUM_DOCS_TO_KEEP:\n",
    "                    try:\n",
    "                        # Validar que es JSON válido antes de escribirlo\n",
    "                        json.loads(line)\n",
    "                        outfile.write(line)\n",
    "                        count += 1\n",
    "                    except json.JSONDecodeError:\n",
    "                        # Omitir líneas que no son JSON válido (si las hay)\n",
    "                        continue\n",
    "                else:\n",
    "                    break # Detenerse una vez que se han procesado suficientes documentos\n",
    "\n",
    "        print(f\"Subconjunto creado con {count} documentos en '{SUBSET_CORPUS_FILE_PATH}'\")\n",
    "else:\n",
    "    print(f\"El archivo subconjunto '{SUBSET_CORPUS_FILE_PATH}' ya existe. ¡Saltando la generación del subconjunto!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f15f702a",
   "metadata": {},
   "source": [
    "## Carga del Corpus y Consultas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f332771e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Corpus de documentos (subset) cargado exitosamente. Número de documentos: 25000\n",
      "Primeros 5 documentos del corpus:\n",
      "          id           submitter  \\\n",
      "0  0704.0001      Pavel Nadolsky   \n",
      "1  0704.0002        Louis Theran   \n",
      "2  0704.0003         Hongjun Pan   \n",
      "3  0704.0004        David Callan   \n",
      "4  0704.0005  Alberto Torchinsky   \n",
      "\n",
      "                                             authors  \\\n",
      "0  C. Bal\\'azs, E. L. Berger, P. M. Nadolsky, C.-...   \n",
      "1                    Ileana Streinu and Louis Theran   \n",
      "2                                        Hongjun Pan   \n",
      "3                                       David Callan   \n",
      "4           Wael Abu-Shammala and Alberto Torchinsky   \n",
      "\n",
      "                                               title  \\\n",
      "0  Calculation of prompt diphoton production cros...   \n",
      "1           Sparsity-certifying Graph Decompositions   \n",
      "2  The evolution of the Earth-Moon system based o...   \n",
      "3  A determinant of Stirling cycle numbers counts...   \n",
      "4  From dyadic $\\Lambda_{\\alpha}$ to $\\Lambda_{\\a...   \n",
      "\n",
      "                                  comments  \\\n",
      "0  37 pages, 15 figures; published version   \n",
      "1    To appear in Graphs and Combinatorics   \n",
      "2                      23 pages, 3 figures   \n",
      "3                                 11 pages   \n",
      "4                                     None   \n",
      "\n",
      "                                 journal-ref                         doi  \\\n",
      "0                   Phys.Rev.D76:013009,2007  10.1103/PhysRevD.76.013009   \n",
      "1                                       None                        None   \n",
      "2                                       None                        None   \n",
      "3                                       None                        None   \n",
      "4  Illinois J. Math. 52 (2008) no.2, 681-689                        None   \n",
      "\n",
      "          report-no       categories  \\\n",
      "0  ANL-HEP-PR-07-12           hep-ph   \n",
      "1              None    math.CO cs.CG   \n",
      "2              None   physics.gen-ph   \n",
      "3              None          math.CO   \n",
      "4              None  math.CA math.FA   \n",
      "\n",
      "                                             license  \\\n",
      "0                                               None   \n",
      "1  http://arxiv.org/licenses/nonexclusive-distrib...   \n",
      "2                                               None   \n",
      "3                                               None   \n",
      "4                                               None   \n",
      "\n",
      "                                            abstract  \\\n",
      "0    A fully differential calculation in perturba...   \n",
      "1    We describe a new algorithm, the $(k,\\ell)$-...   \n",
      "2    The evolution of Earth-Moon system is descri...   \n",
      "3    We show that a determinant of Stirling cycle...   \n",
      "4    In this paper we show how to compute the $\\L...   \n",
      "\n",
      "                                            versions update_date  \\\n",
      "0  [{'version': 'v1', 'created': 'Mon, 2 Apr 2007...  2008-11-26   \n",
      "1  [{'version': 'v1', 'created': 'Sat, 31 Mar 200...  2008-12-13   \n",
      "2  [{'version': 'v1', 'created': 'Sun, 1 Apr 2007...  2008-01-13   \n",
      "3  [{'version': 'v1', 'created': 'Sat, 31 Mar 200...  2007-05-23   \n",
      "4  [{'version': 'v1', 'created': 'Mon, 2 Apr 2007...  2013-10-15   \n",
      "\n",
      "                                      authors_parsed  \n",
      "0  [[Balázs, C., ], [Berger, E. L., ], [Nadolsky,...  \n",
      "1           [[Streinu, Ileana, ], [Theran, Louis, ]]  \n",
      "2                                 [[Pan, Hongjun, ]]  \n",
      "3                                [[Callan, David, ]]  \n",
      "4  [[Abu-Shammala, Wael, ], [Torchinsky, Alberto, ]]  \n",
      "\n",
      "Columnas disponibles en el DataFrame:\n",
      "Index(['id', 'submitter', 'authors', 'title', 'comments', 'journal-ref', 'doi',\n",
      "       'report-no', 'categories', 'license', 'abstract', 'versions',\n",
      "       'update_date', 'authors_parsed'],\n",
      "      dtype='object')\n",
      "\n",
      "Archivo de consultas cargado exitosamente. Número de consultas: 5\n",
      "Consultas cargadas:\n",
      "1. diphoton production cross sections\n",
      "2. quantum chromodynamics\n",
      "3. higgs boson decay\n",
      "4. machine learning for particle physics\n",
      "5. top quark production\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import os \n",
    "\n",
    "# --- CONFIGURACIÓN DE RUTAS DE ARCHIVOS ----\n",
    "SUBSET_CORPUS_FILE_PATH = 'data/arxiv_subset_1_percent.jsonl'\n",
    "QUERIES_FILE_PATH = 'data/queries.txt'\n",
    "# --- Cargar el Corpus de Documentos (usando el SUBSET) ---\n",
    "data = []\n",
    "try:\n",
    "    with open(SUBSET_CORPUS_FILE_PATH, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            data.append(json.loads(line))\n",
    "    df = pd.DataFrame(data)\n",
    "    print(f\"\\nCorpus de documentos (subset) cargado exitosamente. Número de documentos: {len(df)}\")\n",
    "    print(\"Primeros 5 documentos del corpus:\")\n",
    "    print(df.head())\n",
    "    print(\"\\nColumnas disponibles en el DataFrame:\")\n",
    "    print(df.columns)\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: El archivo '{SUBSET_CORPUS_FILE_PATH}' no fue encontrado.\")\n",
    "    print(\"Asegúrate de que la ruta y el nombre del archivo sean correctos y de haber ejecutado la celda anterior para crearlo.\")\n",
    "except json.JSONDecodeError:\n",
    "    print(f\"Error: No se pudo decodificar el archivo JSON '{SUBSET_CORPUS_FILE_PATH}'. Verifica que el formato sea válido (JSON Lines).\")\n",
    "except Exception as e:\n",
    "    print(f\"Ocurrió un error inesperado al cargar el corpus: {e}\")\n",
    "\n",
    "# --- Cargar el Archivo de Consultas ---\n",
    "queries = []\n",
    "try:\n",
    "    with open(QUERIES_FILE_PATH, 'r', encoding='utf-8') as f:\n",
    "        queries = [line.strip() for line in f if line.strip()]\n",
    "    print(f\"\\nArchivo de consultas cargado exitosamente. Número de consultas: {len(queries)}\")\n",
    "    print(\"Consultas cargadas:\")\n",
    "    for i, q in enumerate(queries):\n",
    "        print(f\"{i+1}. {q}\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: El archivo '{QUERIES_FILE_PATH}' no fue encontrado. Asegúrate de que la ruta y el nombre del archivo sean correctos.\")\n",
    "except Exception as e:\n",
    "    print(f\"Ocurrió un error inesperado al cargar las consultas: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55c48ec6",
   "metadata": {},
   "source": [
    "## Implementación del Preprocesamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e02b2083",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Iniciando preprocesamiento de títulos y abstracts...\n",
      "Títulos preprocesados.\n",
      "Abstracts preprocesados.\n",
      "\n",
      "Preprocesamiento completado. Vista previa de los datos preprocesados:\n",
      "          id                                              title  \\\n",
      "0  0704.0001  Calculation of prompt diphoton production cros...   \n",
      "1  0704.0002           Sparsity-certifying Graph Decompositions   \n",
      "2  0704.0003  The evolution of the Earth-Moon system based o...   \n",
      "3  0704.0004  A determinant of Stirling cycle numbers counts...   \n",
      "4  0704.0005  From dyadic $\\Lambda_{\\alpha}$ to $\\Lambda_{\\a...   \n",
      "\n",
      "                                            abstract  \\\n",
      "0    A fully differential calculation in perturba...   \n",
      "1    We describe a new algorithm, the $(k,\\ell)$-...   \n",
      "2    The evolution of Earth-Moon system is descri...   \n",
      "3    We show that a determinant of Stirling cycle...   \n",
      "4    In this paper we show how to compute the $\\L...   \n",
      "\n",
      "                                     processed_title  \\\n",
      "0  calculation prompt diphoton production cross s...   \n",
      "1           sparsity certifying graph decompositions   \n",
      "2  evolution earth moon system based dark matter ...   \n",
      "3  determinant stirling cycle numbers counts unla...   \n",
      "4                                 dyadic alpha alpha   \n",
      "\n",
      "                                  processed_abstract  \\\n",
      "0  fully differential calculation perturbative qu...   \n",
      "1  describe new algorithm k ell pebble game color...   \n",
      "2  evolution earth moon system described dark mat...   \n",
      "3  show determinant stirling cycle numbers counts...   \n",
      "4  paper show compute alpha norm alpha ge using d...   \n",
      "\n",
      "                                      indexable_text  \n",
      "0  calculation prompt diphoton production cross s...  \n",
      "1  sparsity certifying graph decompositions descr...  \n",
      "2  evolution earth moon system based dark matter ...  \n",
      "3  determinant stirling cycle numbers counts unla...  \n",
      "4  dyadic alpha alpha paper show compute alpha no...  \n",
      "\n",
      "Ejemplo detallado de un documento original vs. preprocesado (primer documento):\n",
      "ID: 0704.0001\n",
      "Título original: Calculation of prompt diphoton production cross sections at Tevatron and\n",
      "  LHC energies\n",
      "Abstract original:   A fully differential calculation in perturbative quantum chromodynamics is\n",
      "presented for the production of massive photon pairs at hadron colliders. All\n",
      "next-to-leading order perturbative contributions from quark-antiquark,\n",
      "gluon-(anti)quark, and gluon-gluon subprocesses are included, as well as\n",
      "all-orders resummation of initial-state gluon radiation valid at\n",
      "next-to-next-to-leading logarithmic accuracy. The region of phase space is\n",
      "specified in which the calculation is most reliable. Good agreement is\n",
      "demonstrated with data from the Fermilab Tevatron, and predictions are made for\n",
      "more detailed tests with CDF and DO data. Predictions are shown for\n",
      "distributions of diphoton pairs produced at the energy of the Large Hadron\n",
      "Collider (LHC). Distributions of the diphoton pairs from the decay of a Higgs\n",
      "boson are contrasted with those produced from QCD processes at the LHC, showing\n",
      "that enhanced sensitivity to the signal can be obtained with judicious\n",
      "selection of events.\n",
      "\n",
      "Título preprocesado: calculation prompt diphoton production cross sections tevatron lhc energies\n",
      "Abstract preprocesado: fully differential calculation perturbative quantum chromodynamics presented production massive photon pairs hadron colliders next leading order perturbative contributions quark antiquark gluon anti quark gluon gluon subprocesses included well orders resummation initial state gluon radiation valid next next leading logarithmic accuracy region phase space specified calculation reliable good agreement demonstrated data fermilab tevatron predictions made detailed tests cdf data predictions shown distributions diphoton pairs produced energy large hadron collider lhc distributions diphoton pairs decay higgs boson contrasted produced qcd processes lhc showing enhanced sensitivity signal obtained judicious selection events\n",
      "Texto indexable final: calculation prompt diphoton production cross sections tevatron lhc energies fully differential calculation perturbative quantum chromodynamics presented production massive photon pairs hadron colliders next leading order perturbative contributions quark antiquark gluon anti quark gluon gluon subprocesses included well orders resummation initial state gluon radiation valid next next leading logarithmic accuracy region phase space specified calculation reliable good agreement demonstrated data fermilab tevatron predictions made detailed tests cdf data predictions shown distributions diphoton pairs produced energy large hadron collider lhc distributions diphoton pairs decay higgs boson contrasted produced qcd processes lhc showing enhanced sensitivity signal obtained judicious selection events\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "# Cargar las stopwords \n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def preprocess_text(text):\n",
    "    \"\"\"\n",
    "    Realiza las operaciones de preprocesamiento sobre un texto:\n",
    "    1. Convierte a minúsculas.\n",
    "    2. Elimina signos de puntuación.\n",
    "    3. Tokeniza.\n",
    "    4. Elimina stopwords.\n",
    "    \"\"\"\n",
    "    if not isinstance(text, str):\n",
    "        return \"\" # Retorna cadena vacía para NaN/None\n",
    "\n",
    "    text = text.lower()  # 1. Convertir a minúsculas\n",
    "    # 2. Eliminar signos de puntuación y reemplazar por espacios simples\n",
    "    text = re.sub(r'[^\\w\\s]', ' ', text)\n",
    "    # Eliminar múltiples espacios y recortar extremos\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "\n",
    "    tokens = word_tokenize(text)  # 3. Tokenizar\n",
    "    # 4. Eliminar stopwords y tokens que no son alfabéticos\n",
    "    tokens = [word for word in tokens if word not in stop_words and word.isalpha()]\n",
    "    return \" \".join(tokens)\n",
    "\n",
    "# --- Aplicar Preprocesamiento al DataFrame ---\n",
    "print(\"\\nIniciando preprocesamiento de títulos y abstracts...\")\n",
    "\n",
    "# Preprocesar la columna 'title' y crear 'processed_title'\n",
    "if 'title' in df.columns:\n",
    "    df['processed_title'] = df['title'].apply(preprocess_text)\n",
    "    print(\"Títulos preprocesados.\")\n",
    "else:\n",
    "    print(\"Advertencia: Columna 'title' no encontrada. Creando columna 'processed_title' vacía.\")\n",
    "    df['processed_title'] = \"\"\n",
    "\n",
    "# Preprocesar la columna 'abstract' y crear 'processed_abstract'\n",
    "if 'abstract' in df.columns:\n",
    "    df['processed_abstract'] = df['abstract'].apply(preprocess_text)\n",
    "    print(\"Abstracts preprocesados.\")\n",
    "else:\n",
    "    print(\"Advertencia: Columna 'abstract' no encontrada. Creando columna 'processed_abstract' vacía.\")\n",
    "    df['processed_abstract'] = \"\"\n",
    "\n",
    "# Crear el texto indexable combinando título y resumen procesados\n",
    "df['indexable_text'] = df['processed_title'] + \" \" + df['processed_abstract']\n",
    "\n",
    "# Limpiar cualquier doble espacio que pueda surgir de la concatenación\n",
    "df['indexable_text'] = df['indexable_text'].str.replace(r'\\s+', ' ', regex=True).str.strip()\n",
    "\n",
    "# --- Mostrar Resultados del Preprocesamiento ---\n",
    "print(\"\\nPreprocesamiento completado. Vista previa de los datos preprocesados:\")\n",
    "display_cols = ['id', 'title', 'abstract', 'processed_title', 'processed_abstract', 'indexable_text']\n",
    "display_cols = [col for col in display_cols if col in df.columns] # Solo mostrar columnas existentes\n",
    "\n",
    "print(df[display_cols].head())\n",
    "\n",
    "# Verificar un ejemplo detallado\n",
    "if not df.empty and 'id' in df.columns:\n",
    "    print(\"\\nEjemplo detallado de un documento original vs. preprocesado (primer documento):\")\n",
    "    example_doc_idx = 0\n",
    "    if example_doc_idx < len(df):\n",
    "        example_doc = df.iloc[example_doc_idx]\n",
    "        print(f\"ID: {example_doc.get('id', 'N/A')}\")\n",
    "        print(f\"Título original: {example_doc.get('title', 'N/A')}\")\n",
    "        print(f\"Abstract original: {example_doc.get('abstract', 'N/A')}\")\n",
    "        print(f\"Título preprocesado: {example_doc.get('processed_title', 'N/A')}\")\n",
    "        print(f\"Abstract preprocesado: {example_doc.get('processed_abstract', 'N/A')}\")\n",
    "        print(f\"Texto indexable final: {example_doc.get('indexable_text', 'N/A')}\")\n",
    "    else:\n",
    "        print(\"No hay documentos en el DataFrame para mostrar el ejemplo.\")\n",
    "else:\n",
    "    print(\"El DataFrame está vacío o le falta la columna 'id', no hay datos para preprocesar o mostrar.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "005152f4",
   "metadata": {},
   "source": [
    "## Indexacion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70cfe2be",
   "metadata": {},
   "source": [
    "## Indexación con TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "08a8935a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Paso 2.1: Indexación con TF-IDF ---\n",
      "Matriz TF-IDF creada con forma: (25000, 13752)\n",
      "Número de términos únicos (features) en el vocabulario TF-IDF: 13752\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "print(\"\\n--- Paso 2.1: Indexación con TF-IDF ---\")\n",
    "\n",
    "# Inicializar el vectorizador TF-IDF\n",
    "tfidf_vectorizer = TfidfVectorizer(min_df=5, max_df=0.8)\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(df['indexable_text'])\n",
    "\n",
    "print(f\"Matriz TF-IDF creada con forma: {tfidf_matrix.shape}\")\n",
    "print(f\"Número de términos únicos (features) en el vocabulario TF-IDF: {len(tfidf_vectorizer.get_feature_names_out())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33cea666",
   "metadata": {},
   "source": [
    "## Indexación con BM25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "553beb11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Paso 2.2: Indexación con BM25 ---\n",
      "Modelo BM25 inicializado.\n",
      "Corpus tokenizado para BM25 con 25000 documentos.\n"
     ]
    }
   ],
   "source": [
    "from rank_bm25 import BM25Okapi\n",
    "\n",
    "print(\"\\n--- Paso 2.2: Indexación con BM25 ---\")\n",
    "tokenized_corpus_bm25 = [doc.split(\" \") for doc in df['indexable_text']]\n",
    "bm25_model = BM25Okapi(tokenized_corpus_bm25)\n",
    "\n",
    "print(\"Modelo BM25 inicializado.\")\n",
    "print(f\"Corpus tokenizado para BM25 con {len(tokenized_corpus_bm25)} documentos.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91332168",
   "metadata": {},
   "source": [
    "## Indexación con Embeddings (FAISS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bb2cfc36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Paso 2.3: Indexación con Embeddings (FAISS) ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5993653ce110473ea65b88e0733c57c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\PC\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\PC\\.cache\\huggingface\\hub\\models--sentence-transformers--all-MiniLM-L6-v2. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d656f8ec43134de68e3a33f109201a40",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "179747ef14dd4d4f810e2e9a1bb6febd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "597e5ff726b3468e8557aff96e3c66b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a6e0967442e463fabcab05662043e83",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c2df77b950947808abdbbbbcdfa8608",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13bee44f12694575baa3a5b0a52b07d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b848d38ee29b4d2a847a7c983135df9a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "70676092f9184612b9df853fcf2592e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62b7c48be83949fb99d88700bc2db164",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75e2bc110f9f44b0bc71944b61aad8e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo de embeddings 'all-MiniLM-L6-v2' cargado exitosamente.\n",
      "Generando embeddings para 25000 documentos. Esto puede tomar un tiempo...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5293f148ba644e5a8b5ed5a0fe4dde12",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/782 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embeddings de documentos creados con forma: (25000, 384)\n",
      "Índice FAISS creado con 25000 vectores.\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "import numpy as np\n",
    "import faiss\n",
    "\n",
    "print(\"\\n--- Paso 2.3: Indexación con Embeddings (FAISS) ---\")\n",
    "embedding_model_name = 'all-MiniLM-L6-v2'\n",
    "try:\n",
    "    embedding_model = SentenceTransformer(embedding_model_name)\n",
    "    print(f\"Modelo de embeddings '{embedding_model_name}' cargado exitosamente.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error al cargar el modelo de embeddings '{embedding_model_name}': {e}\")\n",
    "    print(\"Asegúrate de tener conexión a internet o de haber descargado el modelo previamente.\")\n",
    "    embedding_model = None \n",
    "\n",
    "if embedding_model is not None:\n",
    "    # 2. Generar embeddings para todos los documentos\n",
    "    print(f\"Generando embeddings para {len(df)} documentos. Esto puede tomar un tiempo...\")\n",
    "    # Usamos .tolist() para asegurar que la entrada sea una lista de cadenas\n",
    "    document_embeddings = embedding_model.encode(df['indexable_text'].tolist(), show_progress_bar=True)\n",
    "    print(f\"Embeddings de documentos creados con forma: {document_embeddings.shape}\")\n",
    "\n",
    "    # 3. Crear el índice FAISS\n",
    "    # FAISS trabaja con vectores numpy de tipo float32\n",
    "    dimension = document_embeddings.shape[1] # La dimensión de los embeddings generados\n",
    "    faiss_index = faiss.IndexFlatL2(dimension) # IndexFlatL2 usa distancia euclidiana (L2)\n",
    "    faiss_index.add(np.array(document_embeddings).astype('float32')) # Añadir los embeddings al índice\n",
    "\n",
    "    print(f\"Índice FAISS creado con {faiss_index.ntotal} vectores.\")\n",
    "else:\n",
    "    print(\"Saltando la creación del índice FAISS debido a que el modelo de embeddings no se cargó.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f37eee6",
   "metadata": {},
   "source": [
    "# Recuperación"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "724ba7ee",
   "metadata": {},
   "source": [
    "## Implementación de las Funciones de Búsqueda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54e6dcbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "# --- Funciones de Búsqueda ---\n",
    "\n",
    "def search_tfidf(query, top_k=10):\n",
    "    \"\"\"\n",
    "    Realiza una búsqueda utilizando el modelo TF-IDF.\n",
    "    query: La cadena de consulta.\n",
    "    top_k: Número de documentos más relevantes a retornar.\n",
    "    \"\"\"\n",
    "    if 'tfidf_vectorizer' not in globals() or 'tfidf_matrix' not in globals():\n",
    "        print(\"Error: El vectorizador TF-IDF o la matriz no están disponibles. Asegúrate de ejecutar la celda de indexación TF-IDF.\")\n",
    "        return []\n",
    "\n",
    "    processed_query = preprocess_text(query)\n",
    "    if not processed_query:\n",
    "        print(\"Advertencia: La consulta preprocesada está vacía.\")\n",
    "        return []\n",
    "\n",
    "    # Transformar la consulta en un vector TF-IDF\n",
    "    query_vector = tfidf_vectorizer.transform([processed_query])\n",
    "    cosine_similarities = (tfidf_matrix.dot(query_vector.T)).toarray().flatten()\n",
    "    top_indices = cosine_similarities.argsort()[-top_k:][::-1]\n",
    "\n",
    "    results = []\n",
    "    for i_doc in top_indices:\n",
    "        # Asegurarse de que el índice es válido para df\n",
    "        if i_doc < len(df):\n",
    "            doc = df.iloc[i_doc]\n",
    "            results.append({\n",
    "                'id': doc.get('id', 'N/A'),\n",
    "                'title': doc.get('title', 'N/A'),\n",
    "                'abstract_snippet': doc.get('abstract', 'N/A')[:300] + '...' if isinstance(doc.get('abstract'), str) and len(doc.get('abstract')) > 300 else doc.get('abstract', 'N/A')\n",
    "            })\n",
    "    return results\n",
    "\n",
    "def search_bm25(query, top_k=10):\n",
    "    \"\"\"\n",
    "    Realiza una búsqueda utilizando el modelo BM25.\n",
    "    query: La cadena de consulta.\n",
    "    top_k: Número de documentos más relevantes a retornar.\n",
    "    \"\"\"\n",
    "    if 'bm25_model' not in globals() or 'tokenized_corpus_bm25' not in globals():\n",
    "        print(\"Error: El modelo BM25 o el corpus tokenizado no están disponibles. Asegúrate de ejecutar la celda de indexación BM25.\")\n",
    "        return []\n",
    "\n",
    "    processed_query = preprocess_text(query)\n",
    "    if not processed_query:\n",
    "        print(\"Advertencia: La consulta preprocesada está vacía.\")\n",
    "        return []\n",
    "\n",
    "    tokenized_query = processed_query.split(\" \")\n",
    "\n",
    "    # Obtener los scores de relevancia para cada documento\n",
    "    doc_scores = bm25_model.get_scores(tokenized_query)\n",
    "\n",
    "    # Obtener los índices de los top-k documentos más relevantes\n",
    "    top_indices = doc_scores.argsort()[-top_k:][::-1]\n",
    "\n",
    "    results = []\n",
    "    for i_doc in top_indices:\n",
    "        if i_doc < len(df):\n",
    "            doc = df.iloc[i_doc]\n",
    "            results.append({\n",
    "                'id': doc.get('id', 'N/A'),\n",
    "                'title': doc.get('title', 'N/A'),\n",
    "                'abstract_snippet': doc.get('abstract', 'N/A')[:300] + '...' if isinstance(doc.get('abstract'), str) and len(doc.get('abstract')) > 300 else doc.get('abstract', 'N/A')\n",
    "            })\n",
    "    return results\n",
    "\n",
    "def search_faiss(query, top_k=10):\n",
    "    \"\"\"\n",
    "    Realiza una búsqueda utilizando el índice FAISS (basado en embeddings).\n",
    "    query: La cadena de consulta.\n",
    "    top_k: Número de documentos más relevantes a retornar.\n",
    "    \"\"\"\n",
    "    if 'embedding_model' not in globals() or 'faiss_index' not in globals():\n",
    "        print(\"Error: El modelo de embeddings o el índice FAISS no están disponibles. Asegúrate de ejecutar la celda de indexación de Embeddings.\")\n",
    "        return []\n",
    "    if embedding_model is None or faiss_index is None: # Comprobar si se cargaron correctamente\n",
    "        print(\"Error: Modelo de embeddings o índice FAISS no inicializados correctamente.\")\n",
    "        return []\n",
    "\n",
    "    processed_query = preprocess_text(query)\n",
    "    if not processed_query:\n",
    "        print(\"Advertencia: La consulta preprocesada está vacía.\")\n",
    "        return []\n",
    "\n",
    "    # Generar el embedding para la consulta\n",
    "    query_embedding = embedding_model.encode([processed_query])\n",
    "    # FAISS requiere arrays de float32\n",
    "    query_embedding = np.array(query_embedding).astype('float32')\n",
    "\n",
    "    # Realizar la búsqueda en FAISS\n",
    "    # D: Distancias, I: Índices de los documentos recuperados\n",
    "    distances, top_indices = faiss_index.search(query_embedding, top_k)\n",
    "\n",
    "    results = []\n",
    "    for i_doc in top_indices[0]: # top_indices[0] contiene los índices de los top-k resultados para la primera consulta\n",
    "        if i_doc < len(df):\n",
    "            doc = df.iloc[i_doc]\n",
    "            results.append({\n",
    "                'id': doc.get('id', 'N/A'),\n",
    "                'title': doc.get('title', 'N/A'),\n",
    "                'abstract_snippet': doc.get('abstract', 'N/A')[:300] + '...' if isinstance(doc.get('abstract'), str) and len(doc.get('abstract')) > 300 else doc.get('abstract', 'N/A')\n",
    "            })\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "220b7a2f",
   "metadata": {},
   "source": [
    "# RAG"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbeddc7d",
   "metadata": {},
   "source": [
    " ## Implementación del Módulo RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec2dd2f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Paso 4: RAG (Retrieval-Augmented Generation) con Google Gemini Flash ---\n",
      "Modelo Gemini 2.5 Flash cargado exitosamente.\n"
     ]
    }
   ],
   "source": [
    "import google.generativeai as genai\n",
    "import numpy as np # Todavía necesario para FAISS\n",
    "\n",
    "print(\"\\n--- Paso 4: RAG (Retrieval-Augmented Generation) con Google Gemini Flash ---\")\n",
    "\n",
    "# --- 1. Configurar el Cliente de Gemini ---\n",
    "GEMINI_API_KEY = \"AIzaSyAggMkVW2px2MKCrGRWkMHllN75M24Qx4M\" \n",
    "genai.configure(api_key=GEMINI_API_KEY)\n",
    "\n",
    "# --- 2. Cargar el modelo de Gemini ---\n",
    "try:\n",
    "    gemini_model = genai.GenerativeModel('gemini-2.5-flash')\n",
    "    print(\"Modelo Gemini 2.5 Flash cargado exitosamente.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error al cargar el modelo Gemini: {e}\")\n",
    "    gemini_model = None # Manejar el caso de error\n",
    "\n",
    "def generate_rag_response(query, retrieved_docs, max_context_length=3000): # Aumentamos el context_length para Gemini\n",
    "    \"\"\"\n",
    "    Genera una respuesta utilizando el modelo RAG con Gemini.\n",
    "    query: La consulta del usuario.\n",
    "    retrieved_docs: Lista de diccionarios con los documentos recuperados (top-k).\n",
    "    max_context_length: Longitud máxima del contexto a pasar al LLM (en caracteres).\n",
    "    \"\"\"\n",
    "    if gemini_model is None:\n",
    "        return \"Lo siento, el modelo Gemini no pudo cargarse. No puedo generar una respuesta RAG.\"\n",
    "\n",
    "    context_parts = []\n",
    "    # Tomar el top-3 documentos del índice vectorial (FAISS)\n",
    "    # y construir un contexto a partir de sus títulos y abstracts completos.\n",
    "    for i, doc_info in enumerate(retrieved_docs[:3]):\n",
    "        doc_id = doc_info.get('id')\n",
    "        if doc_id:\n",
    "            # Buscar el documento completo en el DataFrame original 'df' usando el ID\n",
    "            original_doc = df[df['id'] == doc_id]\n",
    "            if not original_doc.empty:\n",
    "                title = original_doc.iloc[0].get('title', 'N/A')\n",
    "                abstract = original_doc.iloc[0].get('abstract', 'N/A')\n",
    "                context_parts.append(f\"Documento {i+1} (ID: {doc_id}):\\nTítulo: {title}\\nAbstract: {abstract}\\n\")\n",
    "            else:\n",
    "                context_parts.append(f\"Documento {i+1} (ID: {doc_id}): Contenido no encontrado en el DataFrame original.\\n\")\n",
    "        else:\n",
    "            context_parts.append(f\"Documento {i+1}: ID no disponible.\\n\")\n",
    "\n",
    "    full_context = \"\\n\\n\".join(context_parts)\n",
    "\n",
    "    # Truncar el contexto si es demasiado largo para el modelo de lenguaje\n",
    "    # Gemini 2.5 Flash tiene una ventana de contexto más grande, pero sigue siendo limitada.\n",
    "    if len(full_context) > max_context_length:\n",
    "        full_context = full_context[:max_context_length] + \"\\n[...Contexto truncado...]\"\n",
    "        print(f\"Advertencia: Contexto truncado a {max_context_length} caracteres.\")\n",
    "\n",
    "    print(f\"\\nContexto generado para RAG (fragmento):\\n---\\n{full_context[:500]}...\\n---\")\n",
    "\n",
    "\n",
    "    # Construir el prompt para Gemini\n",
    "    # Pedimos a Gemini que responda la pregunta basándose en el contexto y justifique.\n",
    "    prompt = (\n",
    "        f\"Eres un asistente de investigación de IA. Basado EXCLUSIVAMENTE en la siguiente información \"\n",
    "        f\"proporcionada en los documentos, responde a la pregunta. \"\n",
    "        f\"Luego, justifica brevemente por qué los documentos proporcionados son relevantes para la consulta.\\n\\n\"\n",
    "        f\"--- Documentos de Contexto ---\\n{full_context}\\n\\n\"\n",
    "        f\"--- Pregunta ---\\n{query}\\n\\n\"\n",
    "        f\"--- Respuesta y Justificación ---\"\n",
    "    )\n",
    "\n",
    "    # Generar la respuesta usando el modelo de Gemini\n",
    "    try:\n",
    "        response = gemini_model.generate_content(\n",
    "            contents=prompt,\n",
    "            # Puedes ajustar parámetros como temperature para controlar la creatividad\n",
    "            generation_config=genai.types.GenerationConfig(temperature=0.2)\n",
    "        )\n",
    "        # Acceder al texto generado\n",
    "        answer = response.text\n",
    "        final_response = (\n",
    "            f\"**Pregunta:** {query}\\n\\n\"\n",
    "            f\"**Respuesta Generada (con Gemini):**\\n{answer}\\n\"\n",
    "        )\n",
    "    except Exception as e:\n",
    "        final_response = f\"Ocurrió un error al generar la respuesta RAG con Gemini: {e}. \" \\\n",
    "                         \"Esto podría deberse a un problema de la API, límite de tokens, o contexto demasiado largo.\"\n",
    "        print(final_response) # Imprimir error para depuración\n",
    "\n",
    "    return final_response\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9156c86a",
   "metadata": {},
   "source": [
    "# Evaluación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52bb2203",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Paso 5: Evaluación ---\n",
      "\n",
      "================================================================================\n",
      "--- Evaluando para la Consulta #1: 'diphoton production cross sections' ---\n",
      "================================================================================\n",
      "\n",
      "Realizando búsquedas con cada modelo (top-10)...\n",
      "\n",
      "--- Comparación de Documentos Recuperados (Top-10 IDs) ---\n",
      "TF-IDF IDs: ['0706.2117', '0705.0349', '0706.2813', '0707.2294', '0705.4313', '0707.4589', '0706.0851', '0704.0001', '0708.1443', '0708.1277']\n",
      "BM25 IDs:   ['0709.0422', '0706.2117', '0705.0349', '0706.2813', '0705.4313', '0706.3235', '0707.4589', '0706.0851', '0704.0001', '0708.1277']\n",
      "FAISS IDs:  ['0706.0701', '0709.1026', '0707.2294', '0705.2744', '0705.3884', '0706.0851', '0709.2478', '0704.0001', '0707.2375', '0708.1277']\n",
      "\n",
      "Documentos en común (IDs):\n",
      "  TF-IDF y BM25: 8 documentos - ['0706.2117', '0705.0349', '0706.2813', '0705.4313', '0707.4589', '0706.0851', '0704.0001', '0708.1277']\n",
      "  TF-IDF y FAISS: 4 documentos - ['0708.1277', '0704.0001', '0707.2294', '0706.0851']\n",
      "  BM25 y FAISS: 3 documentos - ['0704.0001', '0708.1277', '0706.0851']\n",
      "  Común a los tres: 3 documentos - ['0704.0001', '0708.1277', '0706.0851']\n",
      "\n",
      "--- Similitud entre Rankings (Documentos coincidentes en Top-10) ---\n",
      "  Coincidencias TF-IDF y BM25: 8 de 10\n",
      "  Coincidencias TF-IDF y FAISS: 4 de 10\n",
      "  Coincidencias BM25 y FAISS: 3 de 10\n",
      "\n",
      "--- Análisis de Diferencias en el Ordenamiento ---\n",
      "Observaciones:\n",
      "  - Los modelos basados en conteo de palabras (TF-IDF, BM25) suelen tener más coincidencias entre sí.\n",
      "  - El modelo de embeddings (FAISS) a menudo recupera documentos semánticamente similares, incluso si no comparten muchas palabras clave exactas con la consulta o con los otros modelos.\n",
      "  - Si hay pocas o ninguna coincidencia entre FAISS y los otros, podría indicar que la consulta es muy específica en términos de palabras clave o que el significado semántico no se alinea bien con las palabras literales.\n",
      "\n",
      "### **Tabla Comparativa de Resultados entre Modelos para esta Consulta**\n",
      "\n",
      "Para la consulta de evaluación: \"diphoton production cross sections\", se obtuvieron los siguientes resultados en el Top-10 de cada modelo:\n",
      "\n",
      "| Modelo     | IDs Recuperados (Top-10)                                                                                                                   |\n",
      "| :--------- | :----------------------------------------------------------------------------------------------------------------------------------------- |\n",
      "| **TF-IDF** | ['0706.2117', '0705.0349', '0706.2813', '0707.2294', '0705.4313', '0707.4589', '0706.0851', '0704.0001', '0708.1443', '0708.1277'] |\n",
      "| **BM25** | ['0709.0422', '0706.2117', '0705.0349', '0706.2813', '0705.4313', '0706.3235', '0707.4589', '0706.0851', '0704.0001', '0708.1277'] |\n",
      "| **FAISS** | ['0706.0701', '0709.1026', '0707.2294', '0705.2744', '0705.3884', '0706.0851', '0709.2478', '0704.0001', '0707.2375', '0708.1277'] |\n",
      "\n",
      "<br>\n",
      "**Coincidencias de Documentos en el Top-10:**\n",
      "\n",
      "La siguiente tabla resume el número de documentos coincidentes en el Top-10 entre cada par de modelos, y los documentos comunes a los tres.\n",
      "\n",
      "| Comparación           | Cantidad de Coincidencias (IDs en Top-10) | IDs de Documentos Coincidentes                                                                                                                                                                                                            |\n",
      "| :-------------------- | :---------------------------------------- | :---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |\n",
      "| **TF-IDF vs BM25** | 8 | ['0706.2117', '0705.0349', '0706.2813', '0705.4313', '0707.4589', '0706.0851', '0704.0001', '0708.1277'] |\n",
      "| **TF-IDF vs FAISS** | 4 | ['0708.1277', '0704.0001', '0707.2294', '0706.0851'] |\n",
      "| **BM25 vs FAISS** | 3 | ['0704.0001', '0708.1277', '0706.0851'] |\n",
      "| **Común a los Tres** | 3 | ['0704.0001', '0708.1277', '0706.0851'] |\n",
      "\n",
      "<br>\n",
      "**Observaciones Cualitativas sobre la Coincidencia:**\n",
      "\n",
      "* **TF-IDF y BM25** suelen mostrar una mayor superposición en sus resultados. Esto se debe a que ambos son modelos basados en la frecuencia de términos y las palabras clave exactas. BM25 a menudo refina la relevancia, pero su fundamento sigue siendo léxico.\n",
      "* **FAISS (Embeddings)** frecuentemente presenta un conjunto de documentos recuperados distinto en comparación con TF-IDF y BM25. Esto resalta la capacidad de los embeddings para capturar la similitud semántica (el significado subyacente) incluso si los documentos no comparten muchas palabras clave exactas con la consulta o entre sí. Las diferencias en los resultados sugieren que los embeddings pueden encontrar documentos conceptualmente relevantes que los métodos léxicos podrían pasar por alto.\n",
      "\n",
      "--- Contenido Detallado de los Documentos Recuperados por FAISS (Top-10) ---\n",
      "1. ID: 0708.1277\n",
      "   Título: Resummation of Hadroproduction Cross-sections at High Energy\n",
      "   Abstract (fragmento):   We reconsider the high energy resummation of photoproduction,\n",
      "electroproduction and hadroproduction cross-sections, in the light of recent\n",
      "progress in the resummation of perturbative parton evolution to NLO in\n",
      "logarithms of Q^2 and x. We show in particular that the when the coupling runs\n",
      "the drama...\n",
      "--------------------\n",
      "2. ID: 0704.0001\n",
      "   Título: Calculation of prompt diphoton production cross sections at Tevatron and\n",
      "  LHC energies\n",
      "   Abstract (fragmento):   A fully differential calculation in perturbative quantum chromodynamics is\n",
      "presented for the production of massive photon pairs at hadron colliders. All\n",
      "next-to-leading order perturbative contributions from quark-antiquark,\n",
      "gluon-(anti)quark, and gluon-gluon subprocesses are included, as well as\n",
      "a...\n",
      "--------------------\n",
      "3. ID: 0705.2744\n",
      "   Título: Distributions for MSSM Higgs boson + jet production at hadron colliders\n",
      "   Abstract (fragmento):   We present pseudorapidity and transverse momentum distributions for the cross\n",
      "section for the production of the lightest neutral Higgs boson in association\n",
      "with a high-p_T hadronic jet, calculated in the framework of the minimal\n",
      "supersymmetric standard model (MSSM). We discuss the theoretical pred...\n",
      "--------------------\n",
      "4. ID: 0709.2478\n",
      "   Título: Unparticle physics in diphoton production at the CERN LHC\n",
      "   Abstract (fragmento):   We have considered the di-photon production with unparticle at LHC. The\n",
      "contributions of spin-0 and spin-2 unparticle to the di-photon production are\n",
      "studied in the invariant mass and other kinematical distributions, along with\n",
      "their dependencies on the model dependent parameters. The signal corre...\n",
      "--------------------\n",
      "5. ID: 0707.2375\n",
      "   Título: Pion Production by Protons on a Thin Beryllium Target at 6.4, 12.3, and\n",
      "  17.5 GeV/c Incident Proton Momenta\n",
      "   Abstract (fragmento):   An analysis of inclusive pion production in proton-beryllium collisions at\n",
      "6.4, 12.3, and 17.5 GeV/c proton beam momentum has been performed. The data\n",
      "were taken by Experiment 910 at the Alternating Gradient Synchrotron at the\n",
      "Brookhaven National Laboratory. The differential $\\pi^+$ and $\\pi^-$ pr...\n",
      "--------------------\n",
      "6. ID: 0706.0851\n",
      "   Título: Electroweak measurements at the Tevatron\n",
      "   Abstract (fragmento):   The increasing size of the data samples recorded by the CDF and DO\n",
      "experiments at the Tevatron enables studies of a wide range of processes\n",
      "involving the electroweak bosons W and Z. Single boson production is now looked\n",
      "at in terms of differential cross sections such as rapidity or transverse\n",
      "mome...\n",
      "--------------------\n",
      "7. ID: 0705.3884\n",
      "   Título: Inclusive electron spectrum in the region of pion production in\n",
      "  electron-nucleus scattering and the effect of the quasi-elastic interaction\n",
      "   Abstract (fragmento):   We have carried out a calculation of the inclusive electron scattering cross\n",
      "section off oxygen in the kinematical region corresponding to beam energies\n",
      "between 700 and 1200 MeV, where quasielastic scattering and single pion\n",
      "production are the dominant reaction mechanisms. The formalism developed ...\n",
      "--------------------\n",
      "8. ID: 0706.0701\n",
      "   Título: Top Pair Production cross-section at the Tevatron\n",
      "   Abstract (fragmento):   An overview of latest top quark pair production cross-sections measured at\n",
      "the Tevatron is given. These measurements have been carried out in the\n",
      "dilepton, lepton+jets and all-jets channels with an integrated luminosity of\n",
      "about 1fb-1. The measurements are consistent with NNLO calculations.\n",
      "\n",
      "--------------------\n",
      "9. ID: 0709.1026\n",
      "   Título: Parton showers from the dipole formalism\n",
      "   Abstract (fragmento):   We present an implementation of a parton shower algorithm for hadron\n",
      "colliders and electron-positron colliders based on the dipole factorisation\n",
      "formulae. The algorithm treats initial-state partons on equal footing with\n",
      "final-state partons. We implemented the algorithm for massless and massive\n",
      "par...\n",
      "--------------------\n",
      "10. ID: 0707.2294\n",
      "   Título: Search for a High-Mass Diphoton State and Limits on Randall-Sundrum\n",
      "  Gravitons at CDF\n",
      "   Abstract (fragmento):   We have performed a search for new particles which decay to two photons using\n",
      "1.2/fb of integrated luminosity from p-pbar collisions at sqrt(s) = 1.96 TeV\n",
      "collected using the CDF II Detector at the Fermilab Tevatron. We find the\n",
      "diphoton mass spectrum to be in agreement with the standard model exp...\n",
      "--------------------\n",
      "\n",
      "--- Análisis de la Respuesta RAG ---\n",
      "Generando respuesta RAG para la consulta: 'diphoton production cross sections' (usando top-3 FAISS docs)\n",
      "\n",
      "Contexto generado para RAG (fragmento):\n",
      "---\n",
      "Documento 1 (ID: 0708.1277):\n",
      "Título: Resummation of Hadroproduction Cross-sections at High Energy\n",
      "Abstract:   We reconsider the high energy resummation of photoproduction,\n",
      "electroproduction and hadroproduction cross-sections, in the light of recent\n",
      "progress in the resummation of perturbative parton evolution to NLO in\n",
      "logarithms of Q^2 and x. We show in particular that the when the coupling runs\n",
      "the dramatic enhancements seen at fixed coupling, due to infrared singularities\n",
      "in the partonic cross...\n",
      "---\n",
      "\n",
      "==================================================\n",
      "Respuesta RAG para Análisis:\n",
      "**Pregunta:** diphoton production cross sections\n",
      "\n",
      "**Respuesta Generada (con Gemini):**\n",
      "Basado EXCLUSIVAMENTE en la información proporcionada:\n",
      "\n",
      "La producción de secciones transversales de diphotones se aborda en el Documento 2 (ID: 0704.0001). Este documento presenta un cálculo completamente diferencial en cromodinámica cuántica perturbativa para la producción de pares de fotones masivos en colisionadores de hadrones. Incluye todas las contribuciones perturbativas de orden siguiente al principal (NLO) de los subprocesos quark-antiquark, gluon-(anti)quark y gluon-gluon, así como la resummación de todos los órdenes de la radiación de gluones de estado inicial válida con precisión logarítmica de orden siguiente al siguiente al principal (NNLL). El cálculo demuestra una buena concordancia con los datos del Tevatron de Fermilab y se presentan predicciones para las distribuciones de pares de diphotones producidos a la energía del Gran Colisionador de Hadrones (LHC). También se contrastan las distribuciones de pares de diphotones de la desintegración de un bosón de Higgs con las producidas a partir de procesos QCD en el LHC.\n",
      "\n",
      "**Justificación:**\n",
      "El Documento 2 (ID: 0704.0001) es directamente relevante para la consulta, ya que su título es \"Calculation of prompt diphoton production cross sections at Tevatron and LHC energies\" y su resumen describe en detalle los cálculos y predicciones para la producción de pares de fotones (diphotones). Los otros documentos no mencionan explícitamente las secciones transversales de producción de diphotones.\n",
      "\n",
      "==================================================\n",
      "\n",
      "--- Criterios de Análisis de la Respuesta RAG ---\n",
      "Para analizar la respuesta RAG, considera lo siguiente:\n",
      "1. ¿La respuesta utiliza la información recuperada de los documentos? (Verifica si hay frases o conceptos de los abstracts/títulos).\n",
      "2. ¿La respuesta es coherente y gramaticalmente correcta?\n",
      "3. ¿La respuesta aborda directamente la consulta?\n",
      "4. ¿La justificación de relevancia proporcionada por Gemini tiene sentido en relación con los documentos?\n",
      "\n",
      "**Conclusión (realiza esta observación manualmente basándote en la salida para esta consulta):**\n",
      " (Escribe aquí tus conclusiones cualitativas sobre la respuesta RAG.)\n",
      "\n",
      "================================================================================\n",
      "\n",
      "\n",
      "================================================================================\n",
      "--- Evaluando para la Consulta #2: 'quantum chromodynamics' ---\n",
      "================================================================================\n",
      "\n",
      "Realizando búsquedas con cada modelo (top-10)...\n",
      "\n",
      "--- Comparación de Documentos Recuperados (Top-10 IDs) ---\n",
      "TF-IDF IDs: ['0705.3170', '0709.1523', '0704.1724', '0704.1737', '0708.0047', '0705.4356', '0707.3996', '0707.0502', '0707.1065', '0706.2623']\n",
      "BM25 IDs:   ['0709.1769', '0705.3170', '0705.4046', '0709.1523', '0704.1724', '0708.0047', '0705.4356', '0707.3996', '0707.0502', '0707.1065']\n",
      "FAISS IDs:  ['0704.3214', '0705.3170', '0707.3539', '0709.1523', '0705.2974', '0705.4356', '0709.0229', '0707.3697', '0707.1065', '0708.0012']\n",
      "\n",
      "Documentos en común (IDs):\n",
      "  TF-IDF y BM25: 8 documentos - ['0705.3170', '0709.1523', '0704.1724', '0708.0047', '0705.4356', '0707.3996', '0707.0502', '0707.1065']\n",
      "  TF-IDF y FAISS: 4 documentos - ['0707.1065', '0705.3170', '0705.4356', '0709.1523']\n",
      "  BM25 y FAISS: 4 documentos - ['0707.1065', '0705.3170', '0705.4356', '0709.1523']\n",
      "  Común a los tres: 4 documentos - ['0707.1065', '0705.3170', '0705.4356', '0709.1523']\n",
      "\n",
      "--- Similitud entre Rankings (Documentos coincidentes en Top-10) ---\n",
      "  Coincidencias TF-IDF y BM25: 8 de 10\n",
      "  Coincidencias TF-IDF y FAISS: 4 de 10\n",
      "  Coincidencias BM25 y FAISS: 4 de 10\n",
      "\n",
      "--- Análisis de Diferencias en el Ordenamiento ---\n",
      "Observaciones:\n",
      "  - Los modelos basados en conteo de palabras (TF-IDF, BM25) suelen tener más coincidencias entre sí.\n",
      "  - El modelo de embeddings (FAISS) a menudo recupera documentos semánticamente similares, incluso si no comparten muchas palabras clave exactas con la consulta o con los otros modelos.\n",
      "  - Si hay pocas o ninguna coincidencia entre FAISS y los otros, podría indicar que la consulta es muy específica en términos de palabras clave o que el significado semántico no se alinea bien con las palabras literales.\n",
      "\n",
      "### **Tabla Comparativa de Resultados entre Modelos para esta Consulta**\n",
      "\n",
      "Para la consulta de evaluación: \"quantum chromodynamics\", se obtuvieron los siguientes resultados en el Top-10 de cada modelo:\n",
      "\n",
      "| Modelo     | IDs Recuperados (Top-10)                                                                                                                   |\n",
      "| :--------- | :----------------------------------------------------------------------------------------------------------------------------------------- |\n",
      "| **TF-IDF** | ['0705.3170', '0709.1523', '0704.1724', '0704.1737', '0708.0047', '0705.4356', '0707.3996', '0707.0502', '0707.1065', '0706.2623'] |\n",
      "| **BM25** | ['0709.1769', '0705.3170', '0705.4046', '0709.1523', '0704.1724', '0708.0047', '0705.4356', '0707.3996', '0707.0502', '0707.1065'] |\n",
      "| **FAISS** | ['0704.3214', '0705.3170', '0707.3539', '0709.1523', '0705.2974', '0705.4356', '0709.0229', '0707.3697', '0707.1065', '0708.0012'] |\n",
      "\n",
      "<br>\n",
      "**Coincidencias de Documentos en el Top-10:**\n",
      "\n",
      "La siguiente tabla resume el número de documentos coincidentes en el Top-10 entre cada par de modelos, y los documentos comunes a los tres.\n",
      "\n",
      "| Comparación           | Cantidad de Coincidencias (IDs en Top-10) | IDs de Documentos Coincidentes                                                                                                                                                                                                            |\n",
      "| :-------------------- | :---------------------------------------- | :---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |\n",
      "| **TF-IDF vs BM25** | 8 | ['0705.3170', '0709.1523', '0704.1724', '0708.0047', '0705.4356', '0707.3996', '0707.0502', '0707.1065'] |\n",
      "| **TF-IDF vs FAISS** | 4 | ['0707.1065', '0705.3170', '0705.4356', '0709.1523'] |\n",
      "| **BM25 vs FAISS** | 4 | ['0707.1065', '0705.3170', '0705.4356', '0709.1523'] |\n",
      "| **Común a los Tres** | 4 | ['0707.1065', '0705.3170', '0705.4356', '0709.1523'] |\n",
      "\n",
      "<br>\n",
      "**Observaciones Cualitativas sobre la Coincidencia:**\n",
      "\n",
      "* **TF-IDF y BM25** suelen mostrar una mayor superposición en sus resultados. Esto se debe a que ambos son modelos basados en la frecuencia de términos y las palabras clave exactas. BM25 a menudo refina la relevancia, pero su fundamento sigue siendo léxico.\n",
      "* **FAISS (Embeddings)** frecuentemente presenta un conjunto de documentos recuperados distinto en comparación con TF-IDF y BM25. Esto resalta la capacidad de los embeddings para capturar la similitud semántica (el significado subyacente) incluso si los documentos no comparten muchas palabras clave exactas con la consulta o entre sí. Las diferencias en los resultados sugieren que los embeddings pueden encontrar documentos conceptualmente relevantes que los métodos léxicos podrían pasar por alto.\n",
      "\n",
      "--- Contenido Detallado de los Documentos Recuperados por FAISS (Top-10) ---\n",
      "1. ID: 0709.1523\n",
      "   Título: String Theory and Quantum Chromodynamics\n",
      "   Abstract (fragmento):   I review recent progress on the connection between string theory and quantum\n",
      "chromodynamics in the context of the gauge/gravity duality. Emphasis is placed\n",
      "on conciseness and conceptual aspects rather than on technical details. Topics\n",
      "covered include the large-Nc limit of gauge theories, the gravi...\n",
      "--------------------\n",
      "2. ID: 0705.4356\n",
      "   Título: Monte Carlo Methods in Quantum Field Theory\n",
      "   Abstract (fragmento):   In these lecture notes some applications of Monte Carlo integration methods\n",
      "in Quantum Field Theory - in particular in Quantum Chromodynamics - are\n",
      "introduced and discussed.\n",
      "\n",
      "--------------------\n",
      "3. ID: 0705.2974\n",
      "   Título: A diagrammatic derivation of the meson effective masses in the neutral\n",
      "  color-flavor-locked phase of Quantum Chromodynamics\n",
      "   Abstract (fragmento):   We offer a diagrammatic derivation of the effective masses of the axial\n",
      "flavor excitations in the electrical and color neutral CFL phase of QCD. In\n",
      "particular we concentrate on the excitations with the quantum numbers of the\n",
      "kaons: we show how their effective chemical potentials, responsible of th...\n",
      "--------------------\n",
      "4. ID: 0707.1065\n",
      "   Título: Connection between some nonperturbative approaches in QCD\n",
      "   Abstract (fragmento):   The connection between two nonperturbative approaches in quantum\n",
      "chromodynamics is considered. The first one is based on a collective coordinate\n",
      "method, the second one on a spin-charge separation. It is shown that both\n",
      "approaches have some close connection: the existence of two condensates which\n",
      "a...\n",
      "--------------------\n",
      "5. ID: 0708.0012\n",
      "   Título: The quantum vs classical aspects of one dimensional electron-phonon\n",
      "  systems revisited by the renormalization group method\n",
      "   Abstract (fragmento):   An extension of the renormalization group method that includes the effect of\n",
      "retardation for the interactions of a fermion gas is used to re-examine the\n",
      "quantum and classical properties of Peierls- like states in one dimension. For\n",
      "models of spinless and spin-1/2 fermions interacting with either i...\n",
      "--------------------\n",
      "6. ID: 0709.0229\n",
      "   Título: Quantum phase transitions and thermodynamics of quantum antiferromagnets\n",
      "  with competing interactions\n",
      "   Abstract (fragmento):   We study the isotropic Heisenberg chain with nearest and next-nearest\n",
      "neighbour interactions. The ground state phase diagram is constructed in\n",
      "dependence on the additonal interactions and an external magnetic field. The\n",
      "thermodynamics is studied by use of finite sets of non-linear integral\n",
      "equatio...\n",
      "--------------------\n",
      "7. ID: 0705.3170\n",
      "   Título: Two interacting GL-equations in High-T$_c$ superconductivity and quantum\n",
      "  chromodynamics\n",
      "   Abstract (fragmento):   The possible connection between High-T$_c$ superconductivity and quantum\n",
      "chromodynamics is considered that is based on two interacting Ginzburg-Landau\n",
      "equations. For High-T$_c$ superconductivity these two equations describe Cooper\n",
      "electrons interacting with different kind of quasi particles (phono...\n",
      "--------------------\n",
      "8. ID: 0707.3697\n",
      "   Título: Chromoelectric response functions for quark-gluon plasma\n",
      "   Abstract (fragmento):   We determine the chromoelectric response of quark-gluon plasma (QGP)\n",
      "systematically within the framework of classical transport equations. The\n",
      "transport equations are set up in the phase space which includes the SU(3)\n",
      "group space corresponding to color (which is a dynamical degree of freedom), in\n",
      "...\n",
      "--------------------\n",
      "9. ID: 0707.3539\n",
      "   Título: Introduction to Quantum Mechanics and the Quantum-Classical transition\n",
      "   Abstract (fragmento):   In this paper we present a survey of the use of differential geometric\n",
      "formalisms to describe Quantum Mechanics. We analyze Schroedinger and\n",
      "Heisenberg frameworks from this perspective and discuss how the momentum map\n",
      "associated to the action of the unitary group on the Hilbert space allows to\n",
      "rel...\n",
      "--------------------\n",
      "10. ID: 0704.3214\n",
      "   Título: (2+1)-Dimensional Quantum Gravity as the Continuum Limit of Causal\n",
      "  Dynamical Triangulations\n",
      "   Abstract (fragmento):   We perform a non-perturbative sum over geometries in a (2+1)-dimensional\n",
      "quantum gravity model given in terms of Causal Dynamical Triangulations.\n",
      "Inspired by the concept of triangulations of product type introduced\n",
      "previously, we impose an additional notion of order on the discrete, causal\n",
      "geometr...\n",
      "--------------------\n",
      "\n",
      "--- Análisis de la Respuesta RAG ---\n",
      "Generando respuesta RAG para la consulta: 'quantum chromodynamics' (usando top-3 FAISS docs)\n",
      "\n",
      "Contexto generado para RAG (fragmento):\n",
      "---\n",
      "Documento 1 (ID: 0709.1523):\n",
      "Título: String Theory and Quantum Chromodynamics\n",
      "Abstract:   I review recent progress on the connection between string theory and quantum\n",
      "chromodynamics in the context of the gauge/gravity duality. Emphasis is placed\n",
      "on conciseness and conceptual aspects rather than on technical details. Topics\n",
      "covered include the large-Nc limit of gauge theories, the gravitational\n",
      "description of gauge theory thermodynamics and hydrodynamics, and\n",
      "confinement/deconfinement thermal pha...\n",
      "---\n",
      "\n",
      "==================================================\n",
      "Respuesta RAG para Análisis:\n",
      "**Pregunta:** quantum chromodynamics\n",
      "\n",
      "**Respuesta Generada (con Gemini):**\n",
      "**Respuesta:**\n",
      "\n",
      "Basado en los documentos proporcionados, la Cromodinámica Cuántica (Quantum Chromodynamics - QCD) es:\n",
      "\n",
      "*   Una teoría cuya conexión con la teoría de cuerdas se revisa en el contexto de la dualidad gauge/gravedad, incluyendo temas como el límite de gran Nc de las teorías gauge, la descripción gravitacional de la termodinámica e hidrodinámica de las teorías gauge, y las transiciones de fase térmicas de confinamiento/desconfinamiento (Documento 1).\n",
      "*   Un campo en el que se aplican los métodos de integración de Monte Carlo (Documento 2).\n",
      "*   Una teoría en la que se realiza una derivación diagramática de las masas efectivas de los mesones (específicamente las excitaciones axiales de sabor con números cuánticos de kaones) en la fase CFL (color-flavor-locked) neutra, analizando cómo surgen sus potenciales químicos efectivos por efectos de bucle y discutiendo el papel de la neutralidad eléctrica y de color en el cálculo microscópico (Documento 3).\n",
      "\n",
      "**Justificación:**\n",
      "\n",
      "Los documentos proporcionados son relevantes para la consulta porque todos mencionan y discuten directamente \"Quantum Chromodynamics\" (o su acrónimo \"QCD\") en sus títulos y/o resúmenes, ofreciendo diferentes perspectivas, aplicaciones y aspectos teóricos relacionados con ella.\n",
      "\n",
      "==================================================\n",
      "\n",
      "--- Criterios de Análisis de la Respuesta RAG ---\n",
      "Para analizar la respuesta RAG, considera lo siguiente:\n",
      "1. ¿La respuesta utiliza la información recuperada de los documentos? (Verifica si hay frases o conceptos de los abstracts/títulos).\n",
      "2. ¿La respuesta es coherente y gramaticalmente correcta?\n",
      "3. ¿La respuesta aborda directamente la consulta?\n",
      "4. ¿La justificación de relevancia proporcionada por Gemini tiene sentido en relación con los documentos?\n",
      "\n",
      "**Conclusión (realiza esta observación manualmente basándote en la salida para esta consulta):**\n",
      " (Escribe aquí tus conclusiones cualitativas sobre la respuesta RAG.)\n",
      "\n",
      "================================================================================\n",
      "\n",
      "\n",
      "================================================================================\n",
      "--- Evaluando para la Consulta #3: 'higgs boson decay' ---\n",
      "================================================================================\n",
      "\n",
      "Realizando búsquedas con cada modelo (top-10)...\n",
      "\n",
      "--- Comparación de Documentos Recuperados (Top-10 IDs) ---\n",
      "TF-IDF IDs: ['0707.0797', '0706.1898', '0705.2090', '0705.1259', '0704.2000', '0709.1586', '0705.2709', '0707.0373', '0707.1591', '0706.4117']\n",
      "BM25 IDs:   ['0708.1939', '0708.0916', '0704.0438', '0705.1259', '0704.2000', '0709.1586', '0705.2709', '0707.0373', '0707.1591', '0706.4117']\n",
      "FAISS IDs:  ['0706.4269', '0708.1939', '0705.2329', '0708.0916', '0705.1259', '0707.0373', '0705.2801', '0708.0248', '0707.3152', '0707.1591']\n",
      "\n",
      "Documentos en común (IDs):\n",
      "  TF-IDF y BM25: 7 documentos - ['0705.1259', '0704.2000', '0707.0373', '0709.1586', '0705.2709', '0707.1591', '0706.4117']\n",
      "  TF-IDF y FAISS: 3 documentos - ['0707.0373', '0707.1591', '0705.1259']\n",
      "  BM25 y FAISS: 5 documentos - ['0708.1939', '0708.0916', '0705.1259', '0707.0373', '0707.1591']\n",
      "  Común a los tres: 3 documentos - ['0707.0373', '0707.1591', '0705.1259']\n",
      "\n",
      "--- Similitud entre Rankings (Documentos coincidentes en Top-10) ---\n",
      "  Coincidencias TF-IDF y BM25: 7 de 10\n",
      "  Coincidencias TF-IDF y FAISS: 3 de 10\n",
      "  Coincidencias BM25 y FAISS: 5 de 10\n",
      "\n",
      "--- Análisis de Diferencias en el Ordenamiento ---\n",
      "Observaciones:\n",
      "  - Los modelos basados en conteo de palabras (TF-IDF, BM25) suelen tener más coincidencias entre sí.\n",
      "  - El modelo de embeddings (FAISS) a menudo recupera documentos semánticamente similares, incluso si no comparten muchas palabras clave exactas con la consulta o con los otros modelos.\n",
      "  - Si hay pocas o ninguna coincidencia entre FAISS y los otros, podría indicar que la consulta es muy específica en términos de palabras clave o que el significado semántico no se alinea bien con las palabras literales.\n",
      "\n",
      "### **Tabla Comparativa de Resultados entre Modelos para esta Consulta**\n",
      "\n",
      "Para la consulta de evaluación: \"higgs boson decay\", se obtuvieron los siguientes resultados en el Top-10 de cada modelo:\n",
      "\n",
      "| Modelo     | IDs Recuperados (Top-10)                                                                                                                   |\n",
      "| :--------- | :----------------------------------------------------------------------------------------------------------------------------------------- |\n",
      "| **TF-IDF** | ['0707.0797', '0706.1898', '0705.2090', '0705.1259', '0704.2000', '0709.1586', '0705.2709', '0707.0373', '0707.1591', '0706.4117'] |\n",
      "| **BM25** | ['0708.1939', '0708.0916', '0704.0438', '0705.1259', '0704.2000', '0709.1586', '0705.2709', '0707.0373', '0707.1591', '0706.4117'] |\n",
      "| **FAISS** | ['0706.4269', '0708.1939', '0705.2329', '0708.0916', '0705.1259', '0707.0373', '0705.2801', '0708.0248', '0707.3152', '0707.1591'] |\n",
      "\n",
      "<br>\n",
      "**Coincidencias de Documentos en el Top-10:**\n",
      "\n",
      "La siguiente tabla resume el número de documentos coincidentes en el Top-10 entre cada par de modelos, y los documentos comunes a los tres.\n",
      "\n",
      "| Comparación           | Cantidad de Coincidencias (IDs en Top-10) | IDs de Documentos Coincidentes                                                                                                                                                                                                            |\n",
      "| :-------------------- | :---------------------------------------- | :---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |\n",
      "| **TF-IDF vs BM25** | 7 | ['0705.1259', '0704.2000', '0707.0373', '0709.1586', '0705.2709', '0707.1591', '0706.4117'] |\n",
      "| **TF-IDF vs FAISS** | 3 | ['0707.0373', '0707.1591', '0705.1259'] |\n",
      "| **BM25 vs FAISS** | 5 | ['0708.1939', '0708.0916', '0705.1259', '0707.0373', '0707.1591'] |\n",
      "| **Común a los Tres** | 3 | ['0707.0373', '0707.1591', '0705.1259'] |\n",
      "\n",
      "<br>\n",
      "**Observaciones Cualitativas sobre la Coincidencia:**\n",
      "\n",
      "* **TF-IDF y BM25** suelen mostrar una mayor superposición en sus resultados. Esto se debe a que ambos son modelos basados en la frecuencia de términos y las palabras clave exactas. BM25 a menudo refina la relevancia, pero su fundamento sigue siendo léxico.\n",
      "* **FAISS (Embeddings)** frecuentemente presenta un conjunto de documentos recuperados distinto en comparación con TF-IDF y BM25. Esto resalta la capacidad de los embeddings para capturar la similitud semántica (el significado subyacente) incluso si los documentos no comparten muchas palabras clave exactas con la consulta o entre sí. Las diferencias en los resultados sugieren que los embeddings pueden encontrar documentos conceptualmente relevantes que los métodos léxicos podrían pasar por alto.\n",
      "\n",
      "--- Contenido Detallado de los Documentos Recuperados por FAISS (Top-10) ---\n",
      "1. ID: 0707.1591\n",
      "   Título: Invisibly decaying Higgs boson in the Littlest Higgs model with T-parity\n",
      "   Abstract (fragmento):   We show that there are regions in the parameter space of the Littlest Higgs\n",
      "model with T-parity, allowed by electroweak precision data, where the Higgs\n",
      "boson can decay invisibly into a pair of heavy photons A_H with a substantial\n",
      "branching ratio. For a symmetry breaking scale f in the range 450-60...\n",
      "--------------------\n",
      "2. ID: 0708.1939\n",
      "   Título: Effect of Charged Scalar Loops on Photonic Decays of a Fermiophobic\n",
      "  Higgs\n",
      "   Abstract (fragmento):   Higgs bosons with very suppressed couplings to fermions (\"Fermiophobic Higgs\n",
      "bosons\", h_f) can decay to two photons (\\gamma\\gamma) with a branching ratio\n",
      "significantly larger than that expected for the Standard Model Higgs boson for\n",
      "m_{h_f}<150 GeV. Such a particle would give a clear signal at the...\n",
      "--------------------\n",
      "3. ID: 0708.0248\n",
      "   Título: Higgs decays in supersymmetric models with light neutralinos\n",
      "   Abstract (fragmento):   In the Minimal Supersymmetric Standard Model, neutralinos lighter than 50 GeV\n",
      "are compatible with all accelerator, precision, and cosmological bounds. Such\n",
      "neutralinos might constitute a relevant decay channel for the Higgs boson,\n",
      "modifying its expected signatures at hadron colliders. We study the...\n",
      "--------------------\n",
      "4. ID: 0707.0373\n",
      "   Título: Search for invisibly decaying Higgs bosons in e+e- -> Zoho production at\n",
      "  sqrt(s) = 183 - 209 GeV\n",
      "   Abstract (fragmento):   A search is performed for Higgs bosons decaying into invisible final states,\n",
      "produced in association with a Zo boson in e+e- collisions at energies between\n",
      "183 and 209 GeV. The search is based on data samples collected by the OPAL\n",
      "detector at LEP corresponding to an integrated luminosity of about ...\n",
      "--------------------\n",
      "5. ID: 0708.0916\n",
      "   Título: Higgs Decay to Gluons at NNLO\n",
      "   Abstract (fragmento):   We present an analytical calculation of the next-to-next-to-leading order\n",
      "corrections to the partial decay width $H\\to gg$ for a Higgs boson in the\n",
      "intermediate mass range. We apply an asymptotic expansion for $M_H\\ll 2M_t$ and\n",
      "compute three terms in the expansion. The leading term confirms the re...\n",
      "--------------------\n",
      "6. ID: 0705.2801\n",
      "   Título: The ATLAS discovery potential for MSSM neutral Higgs bosons decaying to\n",
      "  a mu+mu- pair in the mass range up to 130 GeV\n",
      "   Abstract (fragmento):   Results are presented on the discovery potential for MSSM neutral Higgs\n",
      "bosons in the Mh-{max}scenario. The region of large tan beta, between 15 and\n",
      "50, and mass between ~ 95 and 130 GeV is considered in the framework of the\n",
      "ATLAS experiment at the Large Hadron Collider (LHC), for a centre-of-mass...\n",
      "--------------------\n",
      "7. ID: 0707.3152\n",
      "   Título: New Physics Effects in Higgs Decay to Tau Leptons\n",
      "   Abstract (fragmento):   We study the possible effects of TeV scale new physics (NP) on the rate for\n",
      "Higgs boson decays to charged leptons, focusing on the tau tau channel which\n",
      "can be readily studied at the Large Hadron collider. Using an SU(3)_C X SU(2)_L\n",
      "X U(1)_Y invariant effective theory valid below a NP scale Lambda...\n",
      "--------------------\n",
      "8. ID: 0705.2329\n",
      "   Título: Search for Neutral Higgs Boson Production in the Decay h to tau(mu) tau\n",
      "  with the D0 Detector\n",
      "   Abstract (fragmento):   A search for the production of neutral Higgs bosons decaying into tau tau\n",
      "final states is presented. One of the two tau leptons is required to decay into\n",
      "a muon. The data were collected by the D0 detector and correspond to an\n",
      "integrated luminosity of about 1.0 fb-1. No excess is observed above the...\n",
      "--------------------\n",
      "9. ID: 0705.1259\n",
      "   Título: Towards a measurement of the two-photon decay width of the Higgs boson\n",
      "  at a Photon Collider\n",
      "   Abstract (fragmento):   A study of the measurement of the two photon decay width times the branching\n",
      "ratio of a Higgs boson with the mass of 120 GeV in photon - photon collisions\n",
      "is presented, assuming a gamma-gamma integrated luminosity of 80 fb^-1 in the\n",
      "high energy part of the spectrum. The analysis is based on the re...\n",
      "--------------------\n",
      "10. ID: 0706.4269\n",
      "   Título: Exploring the Di-Photon Decay of a Light Higgs Boson in the MSSM With\n",
      "  Explicit CP Violation\n",
      "   Abstract (fragmento):   The di-photon decay channel of the lightest Higgs boson is considerd as a\n",
      "probe to explore CP violation in the Minimal Supersymmetric Standard Model\n",
      "(MSSM). The scalar/pseudo-scalar mixing is considered along with CP violation\n",
      "entering through the Higgs-sfermion-sfermion couplings, with and withou...\n",
      "--------------------\n",
      "\n",
      "--- Análisis de la Respuesta RAG ---\n",
      "Generando respuesta RAG para la consulta: 'higgs boson decay' (usando top-3 FAISS docs)\n",
      "\n",
      "Contexto generado para RAG (fragmento):\n",
      "---\n",
      "Documento 1 (ID: 0707.1591):\n",
      "Título: Invisibly decaying Higgs boson in the Littlest Higgs model with T-parity\n",
      "Abstract:   We show that there are regions in the parameter space of the Littlest Higgs\n",
      "model with T-parity, allowed by electroweak precision data, where the Higgs\n",
      "boson can decay invisibly into a pair of heavy photons A_H with a substantial\n",
      "branching ratio. For a symmetry breaking scale f in the range 450-600 GeV, the\n",
      "BR(H -> A_H A_H) can be up to 95% for an intermediate mass Higgs, and...\n",
      "---\n",
      "\n",
      "==================================================\n",
      "Respuesta RAG para Análisis:\n",
      "**Pregunta:** higgs boson decay\n",
      "\n",
      "**Respuesta Generada (con Gemini):**\n",
      "Basado EXCLUSIVAMENTE en la información proporcionada en los documentos:\n",
      "\n",
      "El bosón de Higgs puede decaer de varias maneras, incluyendo:\n",
      "\n",
      "*   **Decaimiento invisible:** En el modelo \"Littlest Higgs con T-paridad\", el bosón de Higgs puede decaer de forma invisible en un par de fotones pesados (A_H). Este decaimiento puede tener una razón de ramificación sustancial, llegando hasta el 95% para un Higgs de masa intermedia, y puede aumentar la anchura de decaimiento total del bosón de Higgs en un orden de magnitud en comparación con el Modelo Estándar para masas de Higgs alrededor de 130 GeV (Documento 1).\n",
      "*   **Decaimiento fotónico (a dos fotones):** Los bosones de Higgs fermiofóbicos (con acoplamientos muy suprimidos a fermiones) pueden decaer a dos fotones ($\\gamma\\gamma$) con una razón de ramificación significativamente mayor que la esperada para el bosón de Higgs del Modelo Estándar para masas inferiores a 150 GeV. Este decaimiento puede ser mediado por bucles de bosones W^+ y bosones de Higgs cargados (H^+) (Documento 2).\n",
      "*   **Decaimiento a neutralinos:** En el Modelo Estándar Supersimétrico Mínimo, el Higgs puede decaer en pares de neutralinos (h --> $\\chi\\chi$), lo que podría ser un canal de decaimiento relevante e incluso dominante. Este nuevo canal puede suprimir la razón de ramificación en modos visibles, como h --> $\\gamma\\gamma$ (Documento 3).\n",
      "\n",
      "**Justificación:**\n",
      "Los documentos proporcionados son directamente relevantes para la consulta \"higgs boson decay\" porque cada uno de ellos describe diferentes modos de decaimiento del bosón de Higgs (invisible, fotónico, a neutralinos) en el contexto de diversos modelos teóricos más allá del Modelo Estándar, discutiendo sus razones de ramificación y los factores que los influyen.\n",
      "\n",
      "==================================================\n",
      "\n",
      "--- Criterios de Análisis de la Respuesta RAG ---\n",
      "Para analizar la respuesta RAG, considera lo siguiente:\n",
      "1. ¿La respuesta utiliza la información recuperada de los documentos? (Verifica si hay frases o conceptos de los abstracts/títulos).\n",
      "2. ¿La respuesta es coherente y gramaticalmente correcta?\n",
      "3. ¿La respuesta aborda directamente la consulta?\n",
      "4. ¿La justificación de relevancia proporcionada por Gemini tiene sentido en relación con los documentos?\n",
      "\n",
      "**Conclusión (realiza esta observación manualmente basándote en la salida para esta consulta):**\n",
      " (Escribe aquí tus conclusiones cualitativas sobre la respuesta RAG.)\n",
      "\n",
      "================================================================================\n",
      "\n",
      "\n",
      "================================================================================\n",
      "--- Evaluando para la Consulta #4: 'machine learning for particle physics' ---\n",
      "================================================================================\n",
      "\n",
      "Realizando búsquedas con cada modelo (top-10)...\n",
      "\n",
      "--- Comparación de Documentos Recuperados (Top-10 IDs) ---\n",
      "TF-IDF IDs: ['0706.2602', '0706.4432', '0705.0631', '0707.3574', '0708.1564', '0705.2318', '0708.2377', '0704.3453', '0704.3905', '0705.1038']\n",
      "BM25 IDs:   ['0708.3411', '0704.1319', '0708.1564', '0707.1706', '0707.0930', '0708.0142', '0709.1948', '0705.2318', '0704.3453', '0704.3905']\n",
      "FAISS IDs:  ['0708.1161', '0707.0099', '0704.0131', '0704.0220', '0705.3946', '0707.0930', '0709.2426', '0704.1881', '0704.0224', '0709.0587']\n",
      "\n",
      "Documentos en común (IDs):\n",
      "  TF-IDF y BM25: 4 documentos - ['0704.3905', '0704.3453', '0708.1564', '0705.2318']\n",
      "  TF-IDF y FAISS: 0 documentos - []\n",
      "  BM25 y FAISS: 1 documentos - ['0707.0930']\n",
      "  Común a los tres: 0 documentos - []\n",
      "\n",
      "--- Similitud entre Rankings (Documentos coincidentes en Top-10) ---\n",
      "  Coincidencias TF-IDF y BM25: 4 de 10\n",
      "  Coincidencias TF-IDF y FAISS: 0 de 10\n",
      "  Coincidencias BM25 y FAISS: 1 de 10\n",
      "\n",
      "--- Análisis de Diferencias en el Ordenamiento ---\n",
      "Observaciones:\n",
      "  - Los modelos basados en conteo de palabras (TF-IDF, BM25) suelen tener más coincidencias entre sí.\n",
      "  - El modelo de embeddings (FAISS) a menudo recupera documentos semánticamente similares, incluso si no comparten muchas palabras clave exactas con la consulta o con los otros modelos.\n",
      "  - Si hay pocas o ninguna coincidencia entre FAISS y los otros, podría indicar que la consulta es muy específica en términos de palabras clave o que el significado semántico no se alinea bien con las palabras literales.\n",
      "\n",
      "### **Tabla Comparativa de Resultados entre Modelos para esta Consulta**\n",
      "\n",
      "Para la consulta de evaluación: \"machine learning for particle physics\", se obtuvieron los siguientes resultados en el Top-10 de cada modelo:\n",
      "\n",
      "| Modelo     | IDs Recuperados (Top-10)                                                                                                                   |\n",
      "| :--------- | :----------------------------------------------------------------------------------------------------------------------------------------- |\n",
      "| **TF-IDF** | ['0706.2602', '0706.4432', '0705.0631', '0707.3574', '0708.1564', '0705.2318', '0708.2377', '0704.3453', '0704.3905', '0705.1038'] |\n",
      "| **BM25** | ['0708.3411', '0704.1319', '0708.1564', '0707.1706', '0707.0930', '0708.0142', '0709.1948', '0705.2318', '0704.3453', '0704.3905'] |\n",
      "| **FAISS** | ['0708.1161', '0707.0099', '0704.0131', '0704.0220', '0705.3946', '0707.0930', '0709.2426', '0704.1881', '0704.0224', '0709.0587'] |\n",
      "\n",
      "<br>\n",
      "**Coincidencias de Documentos en el Top-10:**\n",
      "\n",
      "La siguiente tabla resume el número de documentos coincidentes en el Top-10 entre cada par de modelos, y los documentos comunes a los tres.\n",
      "\n",
      "| Comparación           | Cantidad de Coincidencias (IDs en Top-10) | IDs de Documentos Coincidentes                                                                                                                                                                                                            |\n",
      "| :-------------------- | :---------------------------------------- | :---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |\n",
      "| **TF-IDF vs BM25** | 4 | ['0704.3905', '0704.3453', '0708.1564', '0705.2318'] |\n",
      "| **TF-IDF vs FAISS** | 0 | [] |\n",
      "| **BM25 vs FAISS** | 1 | ['0707.0930'] |\n",
      "| **Común a los Tres** | 0 | [] |\n",
      "\n",
      "<br>\n",
      "**Observaciones Cualitativas sobre la Coincidencia:**\n",
      "\n",
      "* **TF-IDF y BM25** suelen mostrar una mayor superposición en sus resultados. Esto se debe a que ambos son modelos basados en la frecuencia de términos y las palabras clave exactas. BM25 a menudo refina la relevancia, pero su fundamento sigue siendo léxico.\n",
      "* **FAISS (Embeddings)** frecuentemente presenta un conjunto de documentos recuperados distinto en comparación con TF-IDF y BM25. Esto resalta la capacidad de los embeddings para capturar la similitud semántica (el significado subyacente) incluso si los documentos no comparten muchas palabras clave exactas con la consulta o entre sí. Las diferencias en los resultados sugieren que los embeddings pueden encontrar documentos conceptualmente relevantes que los métodos léxicos podrían pasar por alto.\n",
      "\n",
      "--- Contenido Detallado de los Documentos Recuperados por FAISS (Top-10) ---\n",
      "1. ID: 0708.1161\n",
      "   Título: A threshold-improved narrow-width approximation for BSM physics\n",
      "   Abstract (fragmento):   A modified narrow-width approximation that allows for O(Gamma/M)-accurate\n",
      "predictions for resonant particle decay with similar intermediate masses is\n",
      "proposed and applied to MSSM processes to demonstrate its importance for\n",
      "searches for particle physics beyond the Standard Model.\n",
      "\n",
      "--------------------\n",
      "2. ID: 0707.0930\n",
      "   Título: Bayesian Learning of Neural Networks for Signal/Background\n",
      "  Discrimination in Particle Physics\n",
      "   Abstract (fragmento):   Neural networks are used extensively in classification problems in particle\n",
      "physics research. Since the training of neural networks can be viewed as a\n",
      "problem of inference, Bayesian learning of neural networks can provide more\n",
      "optimal and robust results than conventional learning methods. We have\n",
      "...\n",
      "--------------------\n",
      "3. ID: 0709.0587\n",
      "   Título: What can we learn from fluctuations of particle ratios?\n",
      "   Abstract (fragmento):   We explain how fluctuations of ratios can constrain and falsify the\n",
      "statistical model of particle production in heavy ion collisions, using $K/\\pi$\n",
      "fluctuations as an example. We define an observable capable of determining\n",
      "which statistical model, if any, governs freeze-out in ultrarelativistic he...\n",
      "--------------------\n",
      "4. ID: 0705.3946\n",
      "   Título: Interactions of Unparticles with Standard Model Particles\n",
      "   Abstract (fragmento):   We study interactions of unparticles ${\\cal {U}}$ of dimension $d_{\\cal {U}}$\n",
      "due to Georgi with Standard Model (SM) fields through effective operators. The\n",
      "unparticles describe the low energy physics of a non-trivial scale invariant\n",
      "sector. Since unparticles come from beyond the SM physics, it is...\n",
      "--------------------\n",
      "5. ID: 0704.1881\n",
      "   Título: Statistical Properties of Many Particle Eigenfunctions\n",
      "   Abstract (fragmento):   Wavefunction correlations and density matrices for few or many particles are\n",
      "derived from the properties of semiclassical energy Green functions. Universal\n",
      "features of fixed energy (microcanonical) random wavefunction correlation\n",
      "functions appear which reflect the emergence of the canonical ensemb...\n",
      "--------------------\n",
      "6. ID: 0707.0099\n",
      "   Título: Energy distributions from three-body decaying many-body resonances\n",
      "   Abstract (fragmento):   We compute energy distributions of three particles emerging from decaying\n",
      "many-body resonances. We reproduce the measured energy distributions from\n",
      "decays of two archetypal states chosen as the lowest $0^{+}$ and\n",
      "$1^{+}$-resonances in $^{12}$C populated in $\\beta$-decays. These states are\n",
      "dominate...\n",
      "--------------------\n",
      "7. ID: 0704.0131\n",
      "   Título: Vacuum Structure and Potential\n",
      "   Abstract (fragmento):   Based on overall experimental observations, especially the pair processes, I\n",
      "developed a model structure of the vacuum along with a basic-particle formation\n",
      "scheme begun in 2000 (with collaborator P-I Johansson). The model consists in\n",
      "that the vacuum is, briefly, filled of neutral but polarizable ...\n",
      "--------------------\n",
      "8. ID: 0704.0224\n",
      "   Título: Are There Mach Cones in Heavy Ion Collisions? Three-Particle\n",
      "  Correlations from STAR\n",
      "   Abstract (fragmento):   We present results from STAR on 3-particle azimuthal correlations for a\n",
      "$3<p_T<4$ GeV/c trigger particle with two softer $1<p_T<2$ GeV/c particles.\n",
      "Results are shown for pp, d+Au and high statistics Au+Au collisions at\n",
      "$\\sqrt{s_{NN}}=200 GeV$. We observe a 3-particle correlation in central Au+Au\n",
      "c...\n",
      "--------------------\n",
      "9. ID: 0709.2426\n",
      "   Título: A realistic interpretation of quantum mechanics. Asymmetric random walks\n",
      "  in a discrete spacetime\n",
      "   Abstract (fragmento):   In this paper, I propose a realistic interpretation (RI) of quantum\n",
      "mechanics, that is, an interpretation according to which a particle follows a\n",
      "definite path in spacetime. The path is not deterministic but it is rather a\n",
      "random walk. However, the probability of each step of the walk is found to\n",
      "...\n",
      "--------------------\n",
      "10. ID: 0704.0220\n",
      "   Título: Three Particle Correlations from STAR\n",
      "   Abstract (fragmento):   Two-particle correlations have shown modification to the away-side shape in\n",
      "central Au+Au collisions relative to $pp$, d+Au and peripheral Au+Au\n",
      "collisions. Different scenarios can explain this modification including: large\n",
      "angle gluon radiation, jets deflected by transverse flow, path length depe...\n",
      "--------------------\n",
      "\n",
      "--- Análisis de la Respuesta RAG ---\n",
      "Generando respuesta RAG para la consulta: 'machine learning for particle physics' (usando top-3 FAISS docs)\n",
      "\n",
      "Contexto generado para RAG (fragmento):\n",
      "---\n",
      "Documento 1 (ID: 0708.1161):\n",
      "Título: A threshold-improved narrow-width approximation for BSM physics\n",
      "Abstract:   A modified narrow-width approximation that allows for O(Gamma/M)-accurate\n",
      "predictions for resonant particle decay with similar intermediate masses is\n",
      "proposed and applied to MSSM processes to demonstrate its importance for\n",
      "searches for particle physics beyond the Standard Model.\n",
      "\n",
      "\n",
      "\n",
      "Documento 2 (ID: 0707.0930):\n",
      "Título: Bayesian Learning of Neural Networks for Signal/Background\n",
      "  Discri...\n",
      "---\n",
      "\n",
      "==================================================\n",
      "Respuesta RAG para Análisis:\n",
      "**Pregunta:** machine learning for particle physics\n",
      "\n",
      "**Respuesta Generada (con Gemini):**\n",
      "Basado EXCLUSIVAMENTE en la información proporcionada:\n",
      "\n",
      "Las redes neuronales se utilizan ampliamente en problemas de clasificación en la investigación de física de partículas. El aprendizaje bayesiano de redes neuronales se ha investigado para la discriminación de señal/fondo, como en la búsqueda de leptoquarks de segunda generación en el Tevatron. Este enfoque puede proporcionar resultados más óptimos y robustos que los métodos de aprendizaje convencionales.\n",
      "\n",
      "**Justificación:**\n",
      "El Documento 2 (ID: 0707.0930) es directamente relevante para la consulta porque explícitamente discute el uso de \"Neural networks\" (redes neuronales), una técnica fundamental de aprendizaje automático, en \"particle physics research\" (investigación de física de partículas) para \"classification problems\" (problemas de clasificación) y \"signal/background discrimination\" (discriminación de señal/fondo), mencionando específicamente el \"Bayesian learning of neural networks\" (aprendizaje bayesiano de redes neuronales). Los otros documentos no abordan el tema del aprendizaje automático en la física de partículas.\n",
      "\n",
      "==================================================\n",
      "\n",
      "--- Criterios de Análisis de la Respuesta RAG ---\n",
      "Para analizar la respuesta RAG, considera lo siguiente:\n",
      "1. ¿La respuesta utiliza la información recuperada de los documentos? (Verifica si hay frases o conceptos de los abstracts/títulos).\n",
      "2. ¿La respuesta es coherente y gramaticalmente correcta?\n",
      "3. ¿La respuesta aborda directamente la consulta?\n",
      "4. ¿La justificación de relevancia proporcionada por Gemini tiene sentido en relación con los documentos?\n",
      "\n",
      "**Conclusión (realiza esta observación manualmente basándote en la salida para esta consulta):**\n",
      " (Escribe aquí tus conclusiones cualitativas sobre la respuesta RAG.)\n",
      "\n",
      "================================================================================\n",
      "\n",
      "\n",
      "================================================================================\n",
      "--- Evaluando para la Consulta #5: 'top quark production' ---\n",
      "================================================================================\n",
      "\n",
      "Realizando búsquedas con cada modelo (top-10)...\n",
      "\n",
      "--- Comparación de Documentos Recuperados (Top-10 IDs) ---\n",
      "TF-IDF IDs: ['0706.1640', '0707.1342', '0709.2625', '0707.1247', '0705.2431', '0706.0282', '0709.2665', '0709.2264', '0706.1984', '0705.3910']\n",
      "BM25 IDs:   ['0709.0365', '0707.1342', '0706.0701', '0705.2788', '0705.2431', '0709.2665', '0708.1225', '0709.2264', '0706.1984', '0707.1550']\n",
      "FAISS IDs:  ['0705.3021', '0707.1342', '0709.2625', '0707.4139', '0707.1247', '0707.2066', '0709.2665', '0706.0037', '0708.1225', '0706.1984']\n",
      "\n",
      "Documentos en común (IDs):\n",
      "  TF-IDF y BM25: 5 documentos - ['0707.1342', '0705.2431', '0709.2665', '0709.2264', '0706.1984']\n",
      "  TF-IDF y FAISS: 5 documentos - ['0707.1342', '0707.1247', '0709.2625', '0709.2665', '0706.1984']\n",
      "  BM25 y FAISS: 4 documentos - ['0708.1225', '0707.1342', '0706.1984', '0709.2665']\n",
      "  Común a los tres: 3 documentos - ['0707.1342', '0706.1984', '0709.2665']\n",
      "\n",
      "--- Similitud entre Rankings (Documentos coincidentes en Top-10) ---\n",
      "  Coincidencias TF-IDF y BM25: 5 de 10\n",
      "  Coincidencias TF-IDF y FAISS: 5 de 10\n",
      "  Coincidencias BM25 y FAISS: 4 de 10\n",
      "\n",
      "--- Análisis de Diferencias en el Ordenamiento ---\n",
      "Observaciones:\n",
      "  - Los modelos basados en conteo de palabras (TF-IDF, BM25) suelen tener más coincidencias entre sí.\n",
      "  - El modelo de embeddings (FAISS) a menudo recupera documentos semánticamente similares, incluso si no comparten muchas palabras clave exactas con la consulta o con los otros modelos.\n",
      "  - Si hay pocas o ninguna coincidencia entre FAISS y los otros, podría indicar que la consulta es muy específica en términos de palabras clave o que el significado semántico no se alinea bien con las palabras literales.\n",
      "\n",
      "### **Tabla Comparativa de Resultados entre Modelos para esta Consulta**\n",
      "\n",
      "Para la consulta de evaluación: \"top quark production\", se obtuvieron los siguientes resultados en el Top-10 de cada modelo:\n",
      "\n",
      "| Modelo     | IDs Recuperados (Top-10)                                                                                                                   |\n",
      "| :--------- | :----------------------------------------------------------------------------------------------------------------------------------------- |\n",
      "| **TF-IDF** | ['0706.1640', '0707.1342', '0709.2625', '0707.1247', '0705.2431', '0706.0282', '0709.2665', '0709.2264', '0706.1984', '0705.3910'] |\n",
      "| **BM25** | ['0709.0365', '0707.1342', '0706.0701', '0705.2788', '0705.2431', '0709.2665', '0708.1225', '0709.2264', '0706.1984', '0707.1550'] |\n",
      "| **FAISS** | ['0705.3021', '0707.1342', '0709.2625', '0707.4139', '0707.1247', '0707.2066', '0709.2665', '0706.0037', '0708.1225', '0706.1984'] |\n",
      "\n",
      "<br>\n",
      "**Coincidencias de Documentos en el Top-10:**\n",
      "\n",
      "La siguiente tabla resume el número de documentos coincidentes en el Top-10 entre cada par de modelos, y los documentos comunes a los tres.\n",
      "\n",
      "| Comparación           | Cantidad de Coincidencias (IDs en Top-10) | IDs de Documentos Coincidentes                                                                                                                                                                                                            |\n",
      "| :-------------------- | :---------------------------------------- | :---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |\n",
      "| **TF-IDF vs BM25** | 5 | ['0707.1342', '0705.2431', '0709.2665', '0709.2264', '0706.1984'] |\n",
      "| **TF-IDF vs FAISS** | 5 | ['0707.1342', '0707.1247', '0709.2625', '0709.2665', '0706.1984'] |\n",
      "| **BM25 vs FAISS** | 4 | ['0708.1225', '0707.1342', '0706.1984', '0709.2665'] |\n",
      "| **Común a los Tres** | 3 | ['0707.1342', '0706.1984', '0709.2665'] |\n",
      "\n",
      "<br>\n",
      "**Observaciones Cualitativas sobre la Coincidencia:**\n",
      "\n",
      "* **TF-IDF y BM25** suelen mostrar una mayor superposición en sus resultados. Esto se debe a que ambos son modelos basados en la frecuencia de términos y las palabras clave exactas. BM25 a menudo refina la relevancia, pero su fundamento sigue siendo léxico.\n",
      "* **FAISS (Embeddings)** frecuentemente presenta un conjunto de documentos recuperados distinto en comparación con TF-IDF y BM25. Esto resalta la capacidad de los embeddings para capturar la similitud semántica (el significado subyacente) incluso si los documentos no comparten muchas palabras clave exactas con la consulta o entre sí. Las diferencias en los resultados sugieren que los embeddings pueden encontrar documentos conceptualmente relevantes que los métodos léxicos podrían pasar por alto.\n",
      "\n",
      "--- Contenido Detallado de los Documentos Recuperados por FAISS (Top-10) ---\n",
      "1. ID: 0707.1342\n",
      "   Título: Top Quark Production and Decay Properties at the Tevatron\n",
      "   Abstract (fragmento):   The latest results from the CDF and D0 collaborations on the top-quark\n",
      "pair-production cross section and limits on electroweak production are\n",
      "presented. Included are measurements of properties of the top quark such as\n",
      "charge, lifetime, and the decay branching ratio t->Wb. In addition to\n",
      "measuremen...\n",
      "--------------------\n",
      "2. ID: 0708.1225\n",
      "   Título: Single production of heavy top quark from the three-site Higgsless model\n",
      "   Abstract (fragmento):   We consider single production of the heavy top quark T predicted by the\n",
      "three-site Higgsless model in future high energy collider experiments, such as\n",
      "the high energy linear e^{+}e^{-} collider (ILC), the linear-ring type $ep$\n",
      "collider (THERA), and the CERN Large Hadron Collider (LHC). Our numeric...\n",
      "--------------------\n",
      "3. ID: 0709.2625\n",
      "   Título: Search for new physics in top events with the D0 detector\n",
      "   Abstract (fragmento):   This review is focused on the search for new processes, performed with top\n",
      "quark events in D{\\O}. It presents four updated or new D{\\O} results. The two\n",
      "first analyses deal with top production properties: they search for a new heavy\n",
      "resonance decaying to top-antitop. The two last results concern t...\n",
      "--------------------\n",
      "4. ID: 0706.0037\n",
      "   Título: Evidence for single top quark production at D0\n",
      "   Abstract (fragmento):   The results of the first analysis to show evidence for production of single\n",
      "top quarks are presented. Using 0.9 fb-1 of data collected with the D0 detector\n",
      "at the Fermilab Tevatron, the analysis is performed in the electron+jets and\n",
      "muon+jets decay modes, taking special care in modeling the large ...\n",
      "--------------------\n",
      "5. ID: 0709.2665\n",
      "   Título: Top Quark Physics at the Tevatron\n",
      "   Abstract (fragmento):   The Tevatron proton-antiproton collider at Fermilab with its centre of mass\n",
      "energy of 1.96 TeV is currently the only source for the production of top\n",
      "quarks. Its increased luminosity and centre of mass energy in Run II allow both\n",
      "collider detectors CDF and D0 to study top quarks with unprecedented...\n",
      "--------------------\n",
      "6. ID: 0706.1984\n",
      "   Título: Measurements of Top Properties at the Tevatron\n",
      "   Abstract (fragmento):   The large data samples of thousands of top events collected at the Tevatron\n",
      "experiments CDF and D0 allow for a variety of measurements to analyze the\n",
      "properties of the top quark. Guided by the question \"Is the top quark observed\n",
      "at the Tevatron really the top quark of the standard model,'' we pres...\n",
      "--------------------\n",
      "7. ID: 0707.4139\n",
      "   Título: Heavy-quark production in gluon fusion at two loops in QCD\n",
      "   Abstract (fragmento):   We present the two-loop virtual QCD corrections to the production of heavy\n",
      "quarks in gluon fusion. The results are exact in the limit when all kinematical\n",
      "invariants are large compared to the mass of the heavy quark up to terms\n",
      "suppressed by powers of the heavy-quark mass. Our derivation uses a si...\n",
      "--------------------\n",
      "8. ID: 0705.3021\n",
      "   Título: Early physics with top quarks at the LHC\n",
      "   Abstract (fragmento):   The ATLAS and CMS experiments are now in their final installation phase and\n",
      "will be soon ready to study the physics of proton-proton collisions at the\n",
      "Large Hadron Collider. The LHC, by producing 2 $t\\bar{t}$ events per second,\n",
      "will provide more than 8 million top events a year at start-up. In thi...\n",
      "--------------------\n",
      "9. ID: 0707.1247\n",
      "   Título: Top Quark Physics at the LHC\n",
      "   Abstract (fragmento):   The Large Hadron Collider (LHC) is expected to provide proton-proton\n",
      "collisions at a centre-of-mass energy of 14 TeV, yielding millions of of top\n",
      "quark events. The top-physics potential of the two general purpose experiments,\n",
      "ATLAS and CMS, is discussed according to state-of-the-art simulation of ...\n",
      "--------------------\n",
      "10. ID: 0707.2066\n",
      "   Título: High p_T Top Quarks at the Large Hadron Collider\n",
      "   Abstract (fragmento):   Many new physics models predict resonances with masses in the TeV range which\n",
      "decay into a pair of top quarks. With its large cross section, t\\bar t\n",
      "production at the Large Hadron Collider (LHC) offers an excellent opportunity\n",
      "to search for such particles. The identification of very energetic top ...\n",
      "--------------------\n",
      "\n",
      "--- Análisis de la Respuesta RAG ---\n",
      "Generando respuesta RAG para la consulta: 'top quark production' (usando top-3 FAISS docs)\n",
      "\n",
      "Contexto generado para RAG (fragmento):\n",
      "---\n",
      "Documento 1 (ID: 0707.1342):\n",
      "Título: Top Quark Production and Decay Properties at the Tevatron\n",
      "Abstract:   The latest results from the CDF and D0 collaborations on the top-quark\n",
      "pair-production cross section and limits on electroweak production are\n",
      "presented. Included are measurements of properties of the top quark such as\n",
      "charge, lifetime, and the decay branching ratio t->Wb. In addition to\n",
      "measurements about the top quark, the selected event samples are used to study\n",
      "the helicity of the W boso...\n",
      "---\n",
      "\n",
      "==================================================\n",
      "Respuesta RAG para Análisis:\n",
      "**Pregunta:** top quark production\n",
      "\n",
      "**Respuesta Generada (con Gemini):**\n",
      "Basado EXCLUSIVAMENTE en la información proporcionada:\n",
      "\n",
      "La producción del quark top se aborda en los documentos de varias maneras:\n",
      "\n",
      "*   **Producción de pares de quark top:** El Documento 1 presenta los últimos resultados de las colaboraciones CDF y D0 sobre la sección transversal de producción de pares de quark top en el Tevatron, así como los límites en la producción electrodébil.\n",
      "*   **Producción individual de quark top pesado:** El Documento 2 considera la producción individual del quark top pesado T, predicho por el modelo sin Higgs de tres sitios, en futuros experimentos de colisionadores de alta energía como ILC, THERA y LHC. Se mencionan procesos específicos como $e^{+}e^{-}\\to t\\bar{T}\\to t\\bar{t}Z$ en ILC y $qb\\to q'T$ en LHC.\n",
      "*   **Propiedades de producción y búsqueda de nueva física:** El Documento 3 se centra en la búsqueda de nueva física en eventos de quark top con el detector D0, incluyendo análisis de las propiedades de producción del top, específicamente la búsqueda de una nueva resonancia pesada que decae a top-antitop.\n",
      "\n",
      "**Justificación:**\n",
      "Los documentos proporcionados son directamente relevantes para la consulta \"top quark production\" porque:\n",
      "*   El Documento 1 discute la \"top-quark pair-production cross section\" y la \"electroweak production\".\n",
      "*   El Documento 2 trata sobre la \"single production of heavy top quark\".\n",
      "*   El Documento 3 se refiere a las \"top production properties\" y la búsqueda de resonancias en la producción de top.\n",
      "\n",
      "==================================================\n",
      "\n",
      "--- Criterios de Análisis de la Respuesta RAG ---\n",
      "Para analizar la respuesta RAG, considera lo siguiente:\n",
      "1. ¿La respuesta utiliza la información recuperada de los documentos? (Verifica si hay frases o conceptos de los abstracts/títulos).\n",
      "2. ¿La respuesta es coherente y gramaticalmente correcta?\n",
      "3. ¿La respuesta aborda directamente la consulta?\n",
      "4. ¿La justificación de relevancia proporcionada por Gemini tiene sentido en relación con los documentos?\n",
      "\n",
      "**Conclusión (realiza esta observación manualmente basándote en la salida para esta consulta):**\n",
      " (Escribe aquí tus conclusiones cualitativas sobre la respuesta RAG.)\n",
      "\n",
      "================================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "print(\"\\n--- Paso 5: Evaluación ---\")\n",
    "\n",
    "# --- 5.1: Evaluación de Modelos de Recuperación (TF-IDF, BM25, FAISS) ---\n",
    "\n",
    "# Itera sobre cada consulta en la lista 'queries'\n",
    "# Asegúrate de que 'queries' haya sido cargado previamente (ej. en Celda 3)\n",
    "for query_idx, evaluation_query in enumerate(queries):\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"--- Evaluando para la Consulta #{query_idx + 1}: '{evaluation_query}' ---\")\n",
    "    print(f\"{'='*80}\")\n",
    "\n",
    "    # Realizar búsquedas con cada modelo (top-10)\n",
    "    # Asegúrate de que search_tfidf, search_bm25, search_faiss estén definidas en celdas anteriores\n",
    "    print(\"\\nRealizando búsquedas con cada modelo (top-10)...\")\n",
    "    tfidf_results = search_tfidf(evaluation_query, top_k=10)\n",
    "    bm25_results = search_bm25(evaluation_query, top_k=10)\n",
    "    faiss_results = search_faiss(evaluation_query, top_k=10)\n",
    "\n",
    "    # Extraer IDs de los resultados\n",
    "    tfidf_ids = {doc['id'] for doc in tfidf_results if 'id' in doc}\n",
    "    bm25_ids = {doc['id'] for doc in bm25_results if 'id' in doc}\n",
    "    faiss_ids = {doc['id'] for doc in faiss_results if 'id' in doc}\n",
    "\n",
    "    # --- Comparación de Resultados ---\n",
    "\n",
    "    print(\"\\n--- Comparación de Documentos Recuperados (Top-10 IDs) ---\")\n",
    "    print(f\"TF-IDF IDs: {list(tfidf_ids)}\")\n",
    "    print(f\"BM25 IDs:   {list(bm25_ids)}\")\n",
    "    print(f\"FAISS IDs:  {list(faiss_ids)}\")\n",
    "\n",
    "    # Documentos en común entre pares de modelos\n",
    "    common_tfidf_bm25 = tfidf_ids.intersection(bm25_ids)\n",
    "    common_tfidf_faiss = tfidf_ids.intersection(faiss_ids)\n",
    "    common_bm25_faiss = bm25_ids.intersection(faiss_ids)\n",
    "    common_all_three = tfidf_ids.intersection(bm25_ids, faiss_ids)\n",
    "\n",
    "    print(f\"\\nDocumentos en común (IDs):\")\n",
    "    print(f\"  TF-IDF y BM25: {len(common_tfidf_bm25)} documentos - {list(common_tfidf_bm25)}\")\n",
    "    print(f\"  TF-IDF y FAISS: {len(common_tfidf_faiss)} documentos - {list(common_tfidf_faiss)}\")\n",
    "    print(f\"  BM25 y FAISS: {len(common_bm25_faiss)} documentos - {list(common_bm25_faiss)}\")\n",
    "    print(f\"  Común a los tres: {len(common_all_three)} documentos - {list(common_all_three)}\")\n",
    "\n",
    "    # --- Diferencias en el Ordenamiento (Simple Coincidencia en Top-K) ---\n",
    "    # La función count_top_k_overlap debe estar definida en una celda anterior\n",
    "    overlap_tfidf_bm25 = count_top_k_overlap(tfidf_results, bm25_results)\n",
    "    overlap_tfidf_faiss = count_top_k_overlap(tfidf_results, faiss_results)\n",
    "    overlap_bm25_faiss = count_top_k_overlap(bm25_results, faiss_results)\n",
    "\n",
    "    print(\"\\n--- Similitud entre Rankings (Documentos coincidentes en Top-10) ---\")\n",
    "    print(f\"  Coincidencias TF-IDF y BM25: {overlap_tfidf_bm25} de 10\")\n",
    "    print(f\"  Coincidencias TF-IDF y FAISS: {overlap_tfidf_faiss} de 10\")\n",
    "    print(f\"  Coincidencias BM25 y FAISS: {overlap_bm25_faiss} de 10\")\n",
    "\n",
    "    # Análisis cualitativo breve sobre el ordenamiento y diferencias\n",
    "    print(\"\\n--- Análisis de Diferencias en el Ordenamiento ---\")\n",
    "    print(\"Observaciones:\")\n",
    "    print(\"  - Los modelos basados en conteo de palabras (TF-IDF, BM25) suelen tener más coincidencias entre sí.\")\n",
    "    print(\"  - El modelo de embeddings (FAISS) a menudo recupera documentos semánticamente similares, incluso si no comparten muchas palabras clave exactas con la consulta o con los otros modelos.\")\n",
    "    print(\"  - Si hay pocas o ninguna coincidencia entre FAISS y los otros, podría indicar que la consulta es muy específica en términos de palabras clave o que el significado semántico no se alinea bien con las palabras literales.\")\n",
    "\n",
    "    # --- Generación de la Tabla Comparativa en Markdown ---\n",
    "    print(\"\\n### **Tabla Comparativa de Resultados entre Modelos para esta Consulta**\")\n",
    "    print(f\"\\nPara la consulta de evaluación: \\\"{evaluation_query}\\\", se obtuvieron los siguientes resultados en el Top-10 de cada modelo:\")\n",
    "    print(\"\\n| Modelo     | IDs Recuperados (Top-10)                                                                                                                   |\")\n",
    "    print(\"| :--------- | :----------------------------------------------------------------------------------------------------------------------------------------- |\")\n",
    "    print(f\"| **TF-IDF** | {list(tfidf_ids)} |\")\n",
    "    print(f\"| **BM25** | {list(bm25_ids)} |\")\n",
    "    print(f\"| **FAISS** | {list(faiss_ids)} |\")\n",
    "\n",
    "    print(\"\\n<br>\") # Salto de línea en Markdown\n",
    "\n",
    "    print(\"**Coincidencias de Documentos en el Top-10:**\")\n",
    "    print(\"\\nLa siguiente tabla resume el número de documentos coincidentes en el Top-10 entre cada par de modelos, y los documentos comunes a los tres.\")\n",
    "    print(\"\\n| Comparación           | Cantidad de Coincidencias (IDs en Top-10) | IDs de Documentos Coincidentes                                                                                                                                                                                                            |\")\n",
    "    print(\"| :-------------------- | :---------------------------------------- | :---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |\")\n",
    "    print(f\"| **TF-IDF vs BM25** | {overlap_tfidf_bm25} | {list(common_tfidf_bm25)} |\")\n",
    "    print(f\"| **TF-IDF vs FAISS** | {overlap_tfidf_faiss} | {list(common_tfidf_faiss)} |\")\n",
    "    print(f\"| **BM25 vs FAISS** | {overlap_bm25_faiss} | {list(common_bm25_faiss)} |\")\n",
    "    print(f\"| **Común a los Tres** | {len(common_all_three)} | {list(common_all_three)} |\")\n",
    "\n",
    "    print(\"\\n<br>\") # Salto de línea en Markdown\n",
    "\n",
    "    print(\"**Observaciones Cualitativas sobre la Coincidencia:**\")\n",
    "    print(\"\\n* **TF-IDF y BM25** suelen mostrar una mayor superposición en sus resultados. Esto se debe a que ambos son modelos basados en la frecuencia de términos y las palabras clave exactas. BM25 a menudo refina la relevancia, pero su fundamento sigue siendo léxico.\")\n",
    "    print(\"* **FAISS (Embeddings)** frecuentemente presenta un conjunto de documentos recuperados distinto en comparación con TF-IDF y BM25. Esto resalta la capacidad de los embeddings para capturar la similitud semántica (el significado subyacente) incluso si los documentos no comparten muchas palabras clave exactas con la consulta o entre sí. Las diferencias en los resultados sugieren que los embeddings pueden encontrar documentos conceptualmente relevantes que los métodos léxicos podrían pasar por alto.\")\n",
    "\n",
    "\n",
    "    # --- NUEVA PARTE: Mostrar contenido de los documentos recuperados por FAISS ---\n",
    "    print(\"\\n--- Contenido Detallado de los Documentos Recuperados por FAISS (Top-10) ---\")\n",
    "    # Reutilizamos la función display_results del Paso 3\n",
    "    if faiss_results:\n",
    "        for i, res in enumerate(faiss_results):\n",
    "            print(f\"{i+1}. ID: {res['id']}\")\n",
    "            print(f\"   Título: {res['title']}\")\n",
    "            print(f\"   Abstract (fragmento): {res['abstract_snippet']}\")\n",
    "            print(\"-\" * 20)\n",
    "    else:\n",
    "        print(\"No hay resultados de FAISS para mostrar.\")\n",
    "\n",
    "    # --- 5.2: Análisis de la Respuesta Generada con RAG ---\n",
    "    print(\"\\n--- Análisis de la Respuesta RAG ---\")\n",
    "    print(f\"Generando respuesta RAG para la consulta: '{evaluation_query}' (usando top-3 FAISS docs)\")\n",
    "    rag_retrieved_docs = search_faiss(evaluation_query, top_k=3) # Obtener los docs para RAG\n",
    "\n",
    "    if rag_retrieved_docs:\n",
    "        # Asegúrate de que generate_rag_response esté definida en una celda anterior\n",
    "        rag_final_answer = generate_rag_response(evaluation_query, rag_retrieved_docs)\n",
    "        print(\"\\n\" + \"=\"*50)\n",
    "        print(\"Respuesta RAG para Análisis:\")\n",
    "        print(rag_final_answer)\n",
    "        print(\"=\"*50)\n",
    "\n",
    "\n",
    "    else:\n",
    "        print(\"No se pudieron recuperar documentos para el análisis RAG.\")\n",
    "    print(f\"\\n{'='*80}\\n\") # Separador para la siguiente consulta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c7d26c8",
   "metadata": {},
   "source": [
    "# Informe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f588e5bc",
   "metadata": {},
   "source": [
    "### **6.1. Implementación de la Arquitectura**\n",
    "\n",
    "La arquitectura del sistema de Recuperación de Información ha sido diseñada e implementada siguiendo un flujo modular, abarcando desde la preparación de los datos hasta la generación de respuestas aumentadas. Se utilizó un entorno de desarrollo en Jupyter Notebook/Visual Studio Code, lo que facilitó la experimentación y el análisis paso a paso.\n",
    "\n",
    "Los componentes clave de la arquitectura son los siguientes:\n",
    "\n",
    "1.  **Ingesta y Preprocesamiento:**\n",
    "    * Se inicia con la carga de un subconjunto del 1% del corpus de artículos científicos de arXiv y un conjunto de consultas.\n",
    "    * Los textos (títulos y resúmenes) son sometidos a un preprocesamiento riguroso que incluye la conversión a minúsculas, eliminación de signos de puntuación y eliminación de stopwords. Esto prepara los datos para una indexación efectiva y reduce el ruido.\n",
    "\n",
    "2.  **Indexación:**\n",
    "    * Los documentos preprocesados son indexados utilizando tres modelos distintos para permitir diversas estrategias de recuperación:\n",
    "        * **TF-IDF (Term Frequency-Inverse Document Frequency):** Un modelo de bolsa de palabras que pondera la importancia de los términos en función de su frecuencia en el documento y en todo el corpus.\n",
    "        * **BM25 (Okapi BM25):** Una función de ranking basada en la probabilidad que mejora la relevancia de los documentos con respecto a la consulta, ajustándose a la longitud del documento y la saturación de términos.\n",
    "        * **Embeddings con FAISS:** Los documentos son transformados en representaciones vectoriales densas (embeddings) utilizando un modelo de lenguaje pre-entrenado (`all-MiniLM-L6-v2`). Estos embeddings capturan el significado semántico de los textos. FAISS (Facebook AI Similarity Search) se utiliza para crear un índice eficiente que permite la búsqueda rápida de vectores similares.\n",
    "\n",
    "3.  **Recuperación:**\n",
    "    * Se implementan funciones de búsqueda específicas para cada modelo de indexación (`search_tfidf`, `search_bm25`, `search_faiss`).\n",
    "    * Estas funciones toman una consulta, la preprocesan y utilizan el índice correspondiente para devolver los documentos más relevantes, mostrando su identificador, título y un fragmento del resumen.\n",
    "\n",
    "4.  **RAG (Retrieval-Augmented Generation):**\n",
    "    * Este módulo integra la recuperación de información con un modelo generativo avanzado.\n",
    "    * Para una consulta dada, se recuperan los 3 documentos más relevantes utilizando el índice vectorial (FAISS).\n",
    "    * El contenido de estos documentos se pasa como contexto a un modelo de lenguaje grande (LLM), específicamente **Google Gemini 2.5 Flash**, configurado a través de la API `google.generativeai`.\n",
    "    * El LLM utiliza este contexto para generar una respuesta coherente a la consulta, que no solo resume la información relevante sino que también puede justificar la elección de los documentos.\n",
    "\n",
    "5.  **Evaluación:**\n",
    "    * Se realiza una comparación cuantitativa y cualitativa de los resultados de recuperación de TF-IDF, BM25 y FAISS. Esto incluye la identificación de documentos comunes en los top-10, diferencias en el ordenamiento y el cálculo de la similitud entre rankings.\n",
    "    * Se lleva a cabo un análisis de la respuesta generada por el módulo RAG, verificando su coherencia y el uso efectivo de la información recuperada.\n",
    "\n",
    "Esta arquitectura modular permite la flexibilidad para experimentar con diferentes modelos de recuperación y la robustez para integrar capacidades avanzadas de generación de lenguaje, proporcionando un sistema completo para la búsqueda y síntesis de información."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25945380",
   "metadata": {},
   "source": [
    "## Tabla comparativa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6c8c26a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "### **6.2. Tabla Comparativa de Resultados entre Modelos**\n",
      "\n",
      "Para la consulta de evaluación: \"diphoton production cross sections\", se obtuvieron los siguientes resultados en el Top-10 de cada modelo:\n",
      "\n",
      "| Modelo     | IDs Recuperados (Top-10)                                                                                                                   |\n",
      "| :--------- | :----------------------------------------------------------------------------------------------------------------------------------------- |\n",
      "| **TF-IDF** | ['0706.2117', '0705.0349', '0706.2813', '0707.2294', '0705.4313', '0707.4589', '0706.0851', '0704.0001', '0708.1443', '0708.1277'] |\n",
      "| **BM25** | ['0709.0422', '0706.2117', '0705.0349', '0706.2813', '0705.4313', '0706.3235', '0707.4589', '0706.0851', '0704.0001', '0708.1277'] |\n",
      "| **FAISS** | ['0706.0701', '0709.1026', '0707.2294', '0705.2744', '0705.3884', '0706.0851', '0709.2478', '0704.0001', '0707.2375', '0708.1277'] |\n",
      "\n",
      "<br>\n",
      "**Coincidencias de Documentos en el Top-10:**\n",
      "\n",
      "La siguiente tabla resume el número de documentos coincidentes en el Top-10 entre cada par de modelos, y los documentos comunes a los tres.\n",
      "\n",
      "| Comparación           | Cantidad de Coincidencias (IDs en Top-10) | IDs de Documentos Coincidentes                                                                                                                                                                                                            |\n",
      "| :-------------------- | :---------------------------------------- | :---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |\n",
      "| **TF-IDF vs BM25** | 8 | ['0706.2117', '0705.0349', '0706.2813', '0705.4313', '0707.4589', '0706.0851', '0704.0001', '0708.1277'] |\n",
      "| **TF-IDF vs FAISS** | 4 | ['0708.1277', '0704.0001', '0707.2294', '0706.0851'] |\n",
      "| **BM25 vs FAISS** | 3 | ['0704.0001', '0708.1277', '0706.0851'] |\n",
      "| **Común a los Tres** | 3 | ['0704.0001', '0708.1277', '0706.0851'] |\n",
      "\n",
      "<br>\n",
      "**Observaciones Cualitativas sobre la Coincidencia:**\n",
      "\n",
      "* **TF-IDF y BM25** suelen mostrar una mayor superposición en sus resultados. Esto se debe a que ambos son modelos basados en la frecuencia de términos y las palabras clave exactas. BM25 a menudo refina la relevancia, pero su fundamento sigue siendo léxico.\n",
      "* **FAISS (Embeddings)** frecuentemente presenta un conjunto de documentos recuperados distinto en comparación con TF-IDF y BM25. Esto resalta la capacidad de los embeddings para capturar la similitud semántica (el significado subyacente) incluso si los documentos no comparten muchas palabras clave exactas con la consulta o entre sí. Las diferencias en los resultados sugieren que los embeddings pueden encontrar documentos conceptualmente relevantes que los métodos léxicos podrían pasar por alto.\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n### **6.2. Tabla Comparativa de Resultados entre Modelos**\")\n",
    "\n",
    "evaluation_query = queries[0] # Tomamos la primera consulta para la evaluación\n",
    "\n",
    "print(f\"\\nPara la consulta de evaluación: \\\"{evaluation_query}\\\", se obtuvieron los siguientes resultados en el Top-10 de cada modelo:\")\n",
    "\n",
    "# Realizar búsquedas con cada modelo (top-10)\n",
    "# Asegúrate de que search_tfidf, search_bm25, search_faiss estén definidas\n",
    "tfidf_results = search_tfidf(evaluation_query, top_k=10)\n",
    "bm25_results = search_bm25(evaluation_query, top_k=10)\n",
    "faiss_results = search_faiss(evaluation_query, top_k=10)\n",
    "\n",
    "# Extraer IDs de los resultados\n",
    "tfidf_ids = {doc['id'] for doc in tfidf_results if 'id' in doc}\n",
    "bm25_ids = {doc['id'] for doc in bm25_results if 'id' in doc}\n",
    "faiss_ids = {doc['id'] for doc in faiss_results if 'id' in doc}\n",
    "\n",
    "# Documentos en común entre pares de modelos\n",
    "common_tfidf_bm25 = tfidf_ids.intersection(bm25_ids)\n",
    "common_tfidf_faiss = tfidf_ids.intersection(faiss_ids)\n",
    "common_bm25_faiss = bm25_ids.intersection(faiss_ids)\n",
    "common_all_three = tfidf_ids.intersection(bm25_ids, faiss_ids)\n",
    "\n",
    "# --- Diferencias en el Ordenamiento (Simple Coincidencia en Top-K) ---\n",
    "# Asegúrate de que count_top_k_overlap esté definida\n",
    "def count_top_k_overlap(list1, list2, k=10):\n",
    "    \"\"\"Cuenta cuántos IDs del top-K de list1 están en el top-K de list2.\"\"\"\n",
    "    set1 = {doc['id'] for doc in list1[:k] if 'id' in doc}\n",
    "    set2 = {doc['id'] for doc in list2[:k] if 'id' in doc}\n",
    "    return len(set1.intersection(set2))\n",
    "\n",
    "overlap_tfidf_bm25 = count_top_k_overlap(tfidf_results, bm25_results)\n",
    "overlap_tfidf_faiss = count_top_k_overlap(tfidf_results, faiss_results)\n",
    "overlap_bm25_faiss = count_top_k_overlap(bm25_results, faiss_results)\n",
    "\n",
    "\n",
    "# --- Impresión de la Tabla Comparativa en Markdown ---\n",
    "print(\"\\n| Modelo     | IDs Recuperados (Top-10)                                                                                                                   |\")\n",
    "print(\"| :--------- | :----------------------------------------------------------------------------------------------------------------------------------------- |\")\n",
    "print(f\"| **TF-IDF** | {list(tfidf_ids)} |\")\n",
    "print(f\"| **BM25** | {list(bm25_ids)} |\")\n",
    "print(f\"| **FAISS** | {list(faiss_ids)} |\")\n",
    "\n",
    "print(\"\\n<br>\") \n",
    "\n",
    "print(\"**Coincidencias de Documentos en el Top-10:**\")\n",
    "print(\"\\nLa siguiente tabla resume el número de documentos coincidentes en el Top-10 entre cada par de modelos, y los documentos comunes a los tres.\")\n",
    "print(\"\\n| Comparación           | Cantidad de Coincidencias (IDs en Top-10) | IDs de Documentos Coincidentes                                                                                                                                                                                                            |\")\n",
    "print(\"| :-------------------- | :---------------------------------------- | :---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |\")\n",
    "print(f\"| **TF-IDF vs BM25** | {overlap_tfidf_bm25} | {list(common_tfidf_bm25)} |\")\n",
    "print(f\"| **TF-IDF vs FAISS** | {overlap_tfidf_faiss} | {list(common_tfidf_faiss)} |\")\n",
    "print(f\"| **BM25 vs FAISS** | {overlap_bm25_faiss} | {list(common_bm25_faiss)} |\")\n",
    "print(f\"| **Común a los Tres** | {len(common_all_three)} | {list(common_all_three)} |\")\n",
    "\n",
    "print(\"\\n<br>\") \n",
    "\n",
    "print(\"**Observaciones Cualitativas sobre la Coincidencia:**\")\n",
    "print(\"\\n* **TF-IDF y BM25** suelen mostrar una mayor superposición en sus resultados. Esto se debe a que ambos son modelos basados en la frecuencia de términos y las palabras clave exactas. BM25 a menudo refina la relevancia, pero su fundamento sigue siendo léxico.\")\n",
    "print(\"* **FAISS (Embeddings)** frecuentemente presenta un conjunto de documentos recuperados distinto en comparación con TF-IDF y BM25. Esto resalta la capacidad de los embeddings para capturar la similitud semántica (el significado subyacente) incluso si los documentos no comparten muchas palabras clave exactas con la consulta o entre sí. Las diferencias en los resultados sugieren que los embeddings pueden encontrar documentos conceptualmente relevantes que los métodos léxicos podrían pasar por alto.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "828bc0a2",
   "metadata": {},
   "source": [
    "## Ejemplo de una consulta y su respuesta generada con RAG."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afd0945d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Ejemplo de RAG para la consulta: 'diphoton production cross sections' ---\n",
      "\n",
      "--- Documentos Recuperados por FAISS (Top-3 para Contexto RAG) ---\n",
      "1. ID: 0708.1277\n",
      "   Título: Resummation of Hadroproduction Cross-sections at High Energy\n",
      "   Abstract (fragmento):   We reconsider the high energy resummation of photoproduction,\n",
      "electroproduction and hadroproduction cross-sections, in the light of recent\n",
      "progress in the resummation of perturbative parton evolution to NLO in\n",
      "logarithms of Q^2 and x. We show in particular that the when the coupling runs\n",
      "the drama...\n",
      "--------------------\n",
      "2. ID: 0704.0001\n",
      "   Título: Calculation of prompt diphoton production cross sections at Tevatron and\n",
      "  LHC energies\n",
      "   Abstract (fragmento):   A fully differential calculation in perturbative quantum chromodynamics is\n",
      "presented for the production of massive photon pairs at hadron colliders. All\n",
      "next-to-leading order perturbative contributions from quark-antiquark,\n",
      "gluon-(anti)quark, and gluon-gluon subprocesses are included, as well as\n",
      "a...\n",
      "--------------------\n",
      "3. ID: 0705.2744\n",
      "   Título: Distributions for MSSM Higgs boson + jet production at hadron colliders\n",
      "   Abstract (fragmento):   We present pseudorapidity and transverse momentum distributions for the cross\n",
      "section for the production of the lightest neutral Higgs boson in association\n",
      "with a high-p_T hadronic jet, calculated in the framework of the minimal\n",
      "supersymmetric standard model (MSSM). We discuss the theoretical pred...\n",
      "--------------------\n",
      "\n",
      "--- Respuesta Generada con RAG ---\n",
      "\n",
      "Contexto generado para RAG (fragmento):\n",
      "---\n",
      "Documento 1 (ID: 0708.1277):\n",
      "Título: Resummation of Hadroproduction Cross-sections at High Energy\n",
      "Abstract:   We reconsider the high energy resummation of photoproduction,\n",
      "electroproduction and hadroproduction cross-sections, in the light of recent\n",
      "progress in the resummation of perturbative parton evolution to NLO in\n",
      "logarithms of Q^2 and x. We show in particular that the when the coupling runs\n",
      "the dramatic enhancements seen at fixed coupling, due to infrared singularities\n",
      "in the partonic cross...\n",
      "---\n",
      "\n",
      "==================================================\n",
      "Respuesta RAG:\n",
      "**Pregunta:** diphoton production cross sections\n",
      "\n",
      "**Respuesta Generada (con Gemini):**\n",
      "**Respuesta:**\n",
      "\n",
      "Según los documentos proporcionados, la sección de producción de diphotones (pares de fotones masivos) se calcula de forma completamente diferencial en cromodinámica cuántica perturbativa para colisionadores de hadrones. Se incluyen todas las contribuciones perturbativas de orden siguiente principal (NLO) de los subprocesos quark-antiquark, gluon-(anti)quark y gluon-gluon, así como la resummación de todos los órdenes de la radiación de gluones del estado inicial, válida con precisión logarítmica de orden siguiente siguiente principal (NNLO). Se demuestra un buen acuerdo con los datos del Tevatron de Fermilab y se hacen predicciones para pruebas más detalladas con datos de CDF y DO, así como para las distribuciones de pares de diphotones producidos a la energía del Gran Colisionador de Hadrones (LHC).\n",
      "\n",
      "**Justificación:**\n",
      "\n",
      "El Documento 2 (ID: 0704.0001) es directamente relevante para la consulta, ya que su título es \"Calculation of prompt diphoton production cross sections at Tevatron and LHC energies\" y su resumen describe en detalle los cálculos y predicciones para la producción de pares de fotones masivos (diphotones) en colisionadores de hadrones. Los Documentos 1 y 3 no abordan específicamente la producción de diphotones.\n",
      "\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "# Usamos la misma consulta de evaluación\n",
    "evaluation_query = queries[0]\n",
    "\n",
    "print(f\"\\n--- Ejemplo de RAG para la consulta: '{evaluation_query}' ---\")\n",
    "\n",
    "print(\"\\n--- Documentos Recuperados por FAISS (Top-3 para Contexto RAG) ---\")\n",
    "# Obtener los top-3 documentos de FAISS para usar como contexto RAG\n",
    "rag_retrieved_docs = search_faiss(evaluation_query, top_k=3)\n",
    "\n",
    "if rag_retrieved_docs:\n",
    "    for i, doc in enumerate(rag_retrieved_docs):\n",
    "        print(f\"{i+1}. ID: {doc['id']}\")\n",
    "        print(f\"   Título: {doc['title']}\")\n",
    "        print(f\"   Abstract (fragmento): {doc['abstract_snippet']}\")\n",
    "        print(\"-\" * 20)\n",
    "else:\n",
    "    print(\"No se pudieron recuperar documentos para el contexto RAG.\")\n",
    "\n",
    "print(\"\\n--- Respuesta Generada con RAG ---\")\n",
    "if rag_retrieved_docs:\n",
    "    rag_final_answer = generate_rag_response(evaluation_query, rag_retrieved_docs)\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"Respuesta RAG:\")\n",
    "    print(rag_final_answer)\n",
    "    print(\"=\"*50)\n",
    "else:\n",
    "    print(\"No se pudo generar una respuesta RAG debido a la falta de documentos recuperados.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "392ac258",
   "metadata": {},
   "source": [
    "## Diferencias entre Modelos y Utilidad del RAG"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "189b0b77",
   "metadata": {},
   "source": [
    "### **6.4. Diferencias entre Modelos y Utilidad del RAG**\n",
    "\n",
    "#### **Diferencias Clave entre Modelos de Recuperación (TF-IDF, BM25, FAISS)**\n",
    "\n",
    "La evaluación de los modelos TF-IDF, BM25 y FAISS ha revelado diferencias fundamentales en cómo abordan la relevancia de los documentos y, por lo tanto, en los resultados que recuperan.\n",
    "\n",
    "* **TF-IDF y BM25 (Modelos Basados en Términos/Lexicales):**\n",
    "    * **Mecanismo:** Ambos se centran en la frecuencia de los términos (palabras clave) en la consulta y en los documentos. TF-IDF pondera la importancia de un término en un documento en relación con su rareza en todo el corpus. BM25 es una mejora probabilística de TF-IDF que maneja mejor la longitud del documento y la saturación de términos.\n",
    "    * **Tipo de Coincidencia:** Son muy efectivos para encontrar documentos que contienen las **palabras clave exactas** de la consulta o sus variantes morfológicas. Su fortaleza radica en la coincidencia léxica.\n",
    "    * **Similitud en Resultados:** Como se observó en la tabla comparativa, TF-IDF y BM25 suelen tener un alto grado de superposición en sus documentos recuperados, ya que ambos operan bajo principios similares de conteo de términos. Las diferencias radican principalmente en el ordenamiento y el ajuste de relevancia de BM25.\n",
    "\n",
    "* **FAISS con Embeddings (Modelo Basado en Semántica/Vectorial):**\n",
    "    * **Mecanismo:** A diferencia de los modelos léxicos, FAISS opera sobre **embeddings** (representaciones vectoriales densas) de los documentos y la consulta. Estos embeddings son generados por modelos de lenguaje pre-entrenados que capturan el significado y el contexto semántico de las palabras y frases. La búsqueda se basa en la similitud de estos vectores en un espacio de alta dimensión.\n",
    "    * **Tipo de Coincidencia:** Su principal ventaja es la capacidad de encontrar documentos que son **semánticamente similares** a la consulta, incluso si no comparten palabras clave explícitas. Esto es crucial para consultas que usan sinónimos, paráfrasis o conceptos relacionados.\n",
    "    * **Diferencias en Resultados:** FAISS a menudo recupera un conjunto de documentos distinto en comparación con TF-IDF y BM25. Esto es una indicación de su capacidad para descubrir conexiones conceptuales que los modelos léxicos podrían pasar por alto. Las bajas coincidencias con los otros modelos no necesariamente significan peor rendimiento, sino una perspectiva de relevancia diferente (semántica vs. léxica).\n",
    "\n",
    "En resumen, mientras que TF-IDF y BM25 sobresalen en la recuperación de documentos por coincidencia de palabras clave, FAISS ofrece una poderosa capacidad de búsqueda semántica, lo cual es invaluable para consultas más complejas o abstractas.\n",
    "\n",
    "#### **Utilidad del RAG (Retrieval-Augmented Generation)**\n",
    "\n",
    "El módulo RAG representa una evolución significativa sobre los sistemas de recuperación de información tradicionales. Su utilidad se manifiesta en varias áreas clave:\n",
    "\n",
    "1.  **Respuestas Sintetizadas y Coherentes:** A diferencia de los sistemas de IR clásicos que solo devuelven una lista de documentos (lo que requiere que el usuario lea y sintetice la información), RAG utiliza un LLM para procesar el contenido de los documentos recuperados y generar una **respuesta directa y coherente** a la consulta del usuario. Esto mejora drásticamente la experiencia del usuario.\n",
    "2.  **Reducción de Alucinaciones:** Al \"anclar\" la generación del LLM en información real y verificable extraída de una base de datos de conocimiento (nuestro corpus), RAG **minimiza el riesgo de que el modelo genere información incorrecta o \"alucine\"** datos que no existen. El LLM opera dentro de los límites del contexto proporcionado.\n",
    "3.  **Justificación y Transparencia:** Como se demostró en el ejemplo, el LLM puede ser instruido para justificar su respuesta haciendo referencia a la información de los documentos fuente. Esto añade una capa de **transparencia** y permite al usuario verificar la procedencia de la información.\n",
    "4.  **Manejo de Información Novedosa o Específica del Dominio:** Los LLMs pre-entrenados tienen un conocimiento vasto, pero limitado a su fecha de entrenamiento. RAG les permite acceder y utilizar información **nueva o muy específica de un dominio** (como artículos científicos recientes en nuestro caso) que no estaba en sus datos de entrenamiento, manteniendo el modelo \"actualizado\" y relevante.\n",
    "5.  **Eficiencia y Costo:** En muchos casos, RAG puede ofrecer un rendimiento comparable al de LLMs mucho más grandes y costosos, o a LLMs finetuneados, al enfocar la generación en un subconjunto relevante de información.\n",
    "\n",
    "En conclusión, RAG transforma un sistema de recuperación de documentos en un verdadero **sistema de respuesta a preguntas**, capaz de comprender consultas complejas y proporcionar respuestas precisas y fundamentadas, lo que lo convierte en una herramienta invaluable para aplicaciones de búsqueda, soporte al cliente, análisis de documentos y más."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
